{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-16T11:02:19.474350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport os\nimport sys\nos.system('git clone https://github.com/tikendraw/caption-generator.git -q')\nos.chdir('caption-generator')\n\n\nif not os.path.exists('funcyou'):\n\tos.system('git clone https://github.com/tikendraw/funcyou -q')\n\nos.system('pip install funcyou/. -q')","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:03:20.191258Z","iopub.execute_input":"2023-05-16T12:03:20.192059Z","iopub.status.idle":"2023-05-16T12:03:36.735265Z","shell.execute_reply.started":"2023-05-16T12:03:20.192026Z","shell.execute_reply":"2023-05-16T12:03:36.734351Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"fatal: destination path 'caption-generator' already exists and is not an empty directory.\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:03:36.736775Z","iopub.execute_input":"2023-05-16T12:03:36.737057Z","iopub.status.idle":"2023-05-16T12:03:37.672303Z","shell.execute_reply.started":"2023-05-16T12:03:36.737035Z","shell.execute_reply":"2023-05-16T12:03:37.671151Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":" Evaluate.txt\t\t\t   get_data.py\n __pycache__\t\t\t   image-caption-generator-deep-learning.ipynb\n'another model.py'\t\t   libdevice.10.bc\n captiongenerator_notebook.ipynb   log\n checkpoints\t\t\t   main.py\n code.txt\t\t\t   model.py\n config.py\t\t\t   preprocessing.py\n data\t\t\t\t   train_notebook.ipynb\n embedding\t\t\t   utils.py\n funcyou\n","output_type":"stream"}]},{"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd\nimport random, math\nimport tensorflow as tf\nimport glob\nimport shutil\nfrom zipfile import ZipFile\nimport datetime\nimport sys\nfrom functools import cache\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport regex as re\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n\nfrom sklearn.model_selection import train_test_split\n\n\nfrom tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocessing\nfrom tensorflow.keras.layers import (\n    TextVectorization, Embedding, LSTM, GRU, Bidirectional, TimeDistributed, Dense, Attention, MultiHeadAttention, Flatten, Dropout,\n    Concatenate, Activation, GlobalAveragePooling2D\n    )\nfrom tensorflow.keras.layers import LSTM, Embedding, Input, Dense, Dropout, Concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Layer\nfrom tensorflow import keras\nfrom tensorflow.keras.utils import array_to_img, img_to_array\nimport string\nfrom tensorflow.keras.callbacks import CSVLogger, EarlyStopping, TensorBoard\nfrom model import LearningRateDecayCallback, get_model, masked_acc, masked_loss\nfrom preprocessing import preprocess_text, embedding_matrix_creater, mapper, clean_words, clean_df\nfrom utils import create_model_checkpoint\n\nfrom config import config\n\nfrom get_data import download_dataset\nfrom funcyou.dataset import download_kaggle_dataset\n\nfrom funcyou.utils import printt, dir_walk\nimport matplotlib.pyplot as plt\nfrom nltk import word_tokenize\nimport nltk\nfrom collections import Counter\nimport regex as re","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:03:40.750587Z","iopub.execute_input":"2023-05-16T12:03:40.751155Z","iopub.status.idle":"2023-05-16T12:04:08.905514Z","shell.execute_reply.started":"2023-05-16T12:03:40.751110Z","shell.execute_reply":"2023-05-16T12:04:08.904328Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n94668760/94668760 [==============================] - 4s 0us/step\n","output_type":"stream"},{"name":"stderr","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"seed_value = 12321\nos.environ['PYTHONHASHSEED'] = str(seed_value)\nrandom.seed(seed_value)\nnp.random.seed(seed_value)\n\n\nBATCH_SIZE =    config.BATCH_SIZE\nIMG_SIZE =      config.IMG_SIZE\nCHANNELS =      config.CHANNELS\nIMG_SHAPE =     config.IMG_SHAPE\nMAX_LEN =       config.MAX_LEN\nEPOCHS =        config.EPOCHS\nLEARNING_RATE = config.LEARNING_RATE\nUNITS =         config.UNITS\nraw_caption_file =  config.raw_caption_file\ncaption_file =  config.caption_file\nimage_dir =     config.image_dir\nglove_path =    config.glove_path\nTEST_SIZE =     config.TEST_SIZE\nVAL_SIZE=       config.VAL_SIZE\nEMBEDDING_DIMENSION =   config.EMBEDDING_DIMENSION ","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:04:08.913231Z","iopub.execute_input":"2023-05-16T12:04:08.913760Z","iopub.status.idle":"2023-05-16T12:04:08.932291Z","shell.execute_reply.started":"2023-05-16T12:04:08.913718Z","shell.execute_reply":"2023-05-16T12:04:08.930509Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(f'''\n{BATCH_SIZE=}\n{IMG_SIZE=}\n{CHANNELS=}\n{IMG_SHAPE=}\n{MAX_LEN=}\n{EPOCHS=}\n{LEARNING_RATE=}\n{UNITS=}\n{raw_caption_file=}\n{caption_file=}\n{image_dir=}\n{glove_path=}\n{TEST_SIZE=}\n{VAL_SIZE=}\n{EMBEDDING_DIMENSION=}\n''')","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:04:08.934912Z","iopub.execute_input":"2023-05-16T12:04:08.935575Z","iopub.status.idle":"2023-05-16T12:04:08.943351Z","shell.execute_reply.started":"2023-05-16T12:04:08.935542Z","shell.execute_reply":"2023-05-16T12:04:08.941837Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\nBATCH_SIZE=8\nIMG_SIZE=256\nCHANNELS=3\nIMG_SHAPE=(256, 256, 3)\nMAX_LEN=50\nEPOCHS=10\nLEARNING_RATE=0.01\nUNITS=16\nraw_caption_file=PosixPath('input/flickr30k/results.csv')\ncaption_file=PosixPath('input/flickr30k/results_cleaned.csv')\nimage_dir=PosixPath('input/flickr30k/images')\nglove_path=PosixPath('embedding/glove.6B.50d.zip')\nTEST_SIZE=0.05\nVAL_SIZE=0.05\nEMBEDDING_DIMENSION=50\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"I had this setting when i tried run in py computer. Now changing according to kaggle","metadata":{}},{"cell_type":"code","source":"# dd = dir_walk('/kaggle/input')\n# dd","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:04:08.946205Z","iopub.execute_input":"2023-05-16T12:04:08.946810Z","iopub.status.idle":"2023-05-16T12:04:08.952924Z","shell.execute_reply.started":"2023-05-16T12:04:08.946779Z","shell.execute_reply":"2023-05-16T12:04:08.951928Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# dd.iloc[4]['directory']","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:04:08.954943Z","iopub.execute_input":"2023-05-16T12:04:08.955679Z","iopub.status.idle":"2023-05-16T12:04:08.961592Z","shell.execute_reply.started":"2023-05-16T12:04:08.955647Z","shell.execute_reply":"2023-05-16T12:04:08.960664Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"caption_file = '/kaggle/input/flickr-image-dataset/flickr30k_images/results.csv'\nimage_dir = '/kaggle/input/flickr-image-dataset/flickr30k_images/flickr30k_images/flickr30k_images'","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:04:08.963007Z","iopub.execute_input":"2023-05-16T12:04:08.963599Z","iopub.status.idle":"2023-05-16T12:04:08.970404Z","shell.execute_reply.started":"2023-05-16T12:04:08.963562Z","shell.execute_reply":"2023-05-16T12:04:08.969672Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(caption_file, sep = '|')\n\n# column names have spaces in them\ndf.columns = df.columns.str.lower().str.strip()\n\n# dropping some values at 19999\ndf.drop(19999, inplace = True) #bad value at 19999\n\ndf['comment_number'] = pd.to_numeric(df['comment_number'])\n\n#removing nulls\ndf.isnull().sum()\ndf = df.dropna()\n\n\nprint(df.info())\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:04:08.971718Z","iopub.execute_input":"2023-05-16T12:04:08.972315Z","iopub.status.idle":"2023-05-16T12:04:09.760262Z","shell.execute_reply.started":"2023-05-16T12:04:08.972283Z","shell.execute_reply":"2023-05-16T12:04:09.759227Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 158914 entries, 0 to 158914\nData columns (total 3 columns):\n #   Column          Non-Null Count   Dtype \n---  ------          --------------   ----- \n 0   image_name      158914 non-null  object\n 1   comment_number  158914 non-null  int64 \n 2   comment         158914 non-null  object\ndtypes: int64(1), object(2)\nmemory usage: 4.8+ MB\nNone\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"       image_name  comment_number  \\\n0  1000092795.jpg               0   \n1  1000092795.jpg               1   \n2  1000092795.jpg               2   \n3  1000092795.jpg               3   \n4  1000092795.jpg               4   \n\n                                             comment  \n0   Two young guys with shaggy hair look at their...  \n1   Two young , White males are outside near many...  \n2   Two men in green shirts are standing in a yard .  \n3       A man in a blue shirt standing in a garden .  \n4            Two friends enjoy time spent together .  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>comment_number</th>\n      <th>comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000092795.jpg</td>\n      <td>0</td>\n      <td>Two young guys with shaggy hair look at their...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000092795.jpg</td>\n      <td>1</td>\n      <td>Two young , White males are outside near many...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000092795.jpg</td>\n      <td>2</td>\n      <td>Two men in green shirts are standing in a yard .</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000092795.jpg</td>\n      <td>3</td>\n      <td>A man in a blue shirt standing in a garden .</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000092795.jpg</td>\n      <td>4</td>\n      <td>Two friends enjoy time spent together .</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# get all unique words by count\ndef word_count_df(x:pd.Series):\n    text_data = x.str.lower().str.cat(sep=' ')\n    words = word_tokenize(text_data) \n    word_count = Counter(words)\n    unique_words = set(words)\n    len(word_count.keys()), len(word_count.values())\n\n    countdf = pd.DataFrame([word_count.keys(), word_count.values()]).T\n    countdf.columns = ['word', 'counts']\n    return countdf\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:04:09.761903Z","iopub.execute_input":"2023-05-16T12:04:09.762631Z","iopub.status.idle":"2023-05-16T12:04:09.770086Z","shell.execute_reply.started":"2023-05-16T12:04:09.762594Z","shell.execute_reply":"2023-05-16T12:04:09.769109Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"countdf = word_count_df(df['comment'])\ncountdf.sort_values('counts', ascending = False).head()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:04:09.771358Z","iopub.execute_input":"2023-05-16T12:04:09.771812Z","iopub.status.idle":"2023-05-16T12:04:36.777829Z","shell.execute_reply.started":"2023-05-16T12:04:09.771778Z","shell.execute_reply":"2023-05-16T12:04:36.776927Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"   word  counts\n29    a  271704\n16    .  151059\n13   in   83466\n14  the   62978\n51   on   45669","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>counts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>29</th>\n      <td>a</td>\n      <td>271704</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>.</td>\n      <td>151059</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>in</td>\n      <td>83466</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>the</td>\n      <td>62978</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>on</td>\n      <td>45669</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# removing low frequency words, they aren't contributing much\nlow_freq_words_df = countdf[countdf.counts<5]\nprint('low freq words : ',len(low_freq_words_df))\nprint(low_freq_words_df.word.values[:100])","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:04:36.782005Z","iopub.execute_input":"2023-05-16T12:04:36.782996Z","iopub.status.idle":"2023-05-16T12:04:36.794412Z","shell.execute_reply.started":"2023-05-16T12:04:36.782956Z","shell.execute_reply":"2023-05-16T12:04:36.793481Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"low freq words :  12561\n['spent' 'stitching' 'sequence' 'tractors' 'cruises' 'sifter' 'bundt'\n 'fingerpaints' 'instrumentalists' 'curtained' 'portrayed' 'blitz'\n 'toothpick' 'origami' 'justin' 'bieber' 'urinals' 'urinal' 'obliverate'\n 'uniformly' 'colleges' 'meetings' 'checkpoint' 'advertise'\n 'single-person' '4-wheeled' 'gamecube' 'picnicking' 'aross' 'mottled'\n 'placards' 'belays' 'supple' 'sheared' 'spaceship' 'hutch' 'decipher'\n 'tonight' 'questioning' 'frolicks' 'crampons' 'disregarding' 'slush'\n 'snowmobiling' 'lucky' 'prescription' 'spectrum' 'month' 'sellers' 'jail'\n 'band-aid' 'life-vest' 'black-colored' 'filler' 'lowly' 'entrees'\n 'hesitates' 'suns' 'relatives' 'moutains' 'connects' 'tree-covered'\n 'multiracial' 'bassoon' 'beanies' 'explained' 'somethings' 'betty' 'boop'\n 'noddles' 'papayas' 'septic' 'oblong' 'whimsically' 'pantaloons'\n 'cradled' 'relevance' 'cobs' 'sheath' 'unsheathes' 'riverbed' 'snapshot'\n 'appetizers' 'pillow-fight' 'i-beam' 'blender' 'magizine' 'overshirt'\n 'chrome' 'deployment' 'omelet' 'alarm' 'on-duty' 'yellow-and-black'\n 'coke-a-cola' 'miss' 'apprentice' 'drifts' 'hovel' 'steadied']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"we are keeping words in comments which atleast has occured  5 times( there are unnecessary word which we don't want) \nthere are ~12000 words that doesn't even gets repeated 5 times in 150000 lines","metadata":{}},{"cell_type":"code","source":"words_to_keep=set(countdf[countdf['counts']>4].word.values)\nlen(words_to_keep)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:04:36.795602Z","iopub.execute_input":"2023-05-16T12:04:36.796245Z","iopub.status.idle":"2023-05-16T12:04:36.811209Z","shell.execute_reply.started":"2023-05-16T12:04:36.796212Z","shell.execute_reply":"2023-05-16T12:04:36.810388Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"7732"},"metadata":{}}]},{"cell_type":"code","source":"# now removing words not in words_to_keep\n\ndef clean_words(x, words_to_keep):\n    words = re.split(r'\\W+', x)\n    return ' '.join(w for w in words if w.lower() in words_to_keep)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:04:36.812290Z","iopub.execute_input":"2023-05-16T12:04:36.812562Z","iopub.status.idle":"2023-05-16T12:04:36.817416Z","shell.execute_reply.started":"2023-05-16T12:04:36.812541Z","shell.execute_reply":"2023-05-16T12:04:36.816576Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df['comment'] = df['comment'].map(lambda x: clean_words(x,words_to_keep=words_to_keep))\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:04:36.818842Z","iopub.execute_input":"2023-05-16T12:04:36.819469Z","iopub.status.idle":"2023-05-16T12:04:40.521272Z","shell.execute_reply.started":"2023-05-16T12:04:36.819433Z","shell.execute_reply":"2023-05-16T12:04:40.520316Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# adding start and end token\n\nSTART_TOKEN = 'startseq'\nEND_TOKEN = 'endseq'\n\ndf['comment'] = START_TOKEN + ' ' + df['comment'] + ' ' + END_TOKEN\n\n# image_path\ndf['image_path'] = str(image_dir) + '/' + df['image_name']\n\n# word_length\ndf['word_length'] = df['comment'].apply(lambda x: len(str(x).split()))\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:04:40.522804Z","iopub.execute_input":"2023-05-16T12:04:40.523161Z","iopub.status.idle":"2023-05-16T12:04:40.852937Z","shell.execute_reply.started":"2023-05-16T12:04:40.523128Z","shell.execute_reply":"2023-05-16T12:04:40.851945Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df['img_exists'] = df['image_path'].apply(lambda x: os.path.isfile(x))","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:04:40.854348Z","iopub.execute_input":"2023-05-16T12:04:40.854733Z","iopub.status.idle":"2023-05-16T12:06:20.118918Z","shell.execute_reply.started":"2023-05-16T12:04:40.854692Z","shell.execute_reply":"2023-05-16T12:06:20.117961Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:06:20.120480Z","iopub.execute_input":"2023-05-16T12:06:20.121172Z","iopub.status.idle":"2023-05-16T12:06:20.134989Z","shell.execute_reply.started":"2023-05-16T12:06:20.121138Z","shell.execute_reply":"2023-05-16T12:06:20.133669Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"       image_name  comment_number  \\\n0  1000092795.jpg               0   \n1  1000092795.jpg               1   \n2  1000092795.jpg               2   \n3  1000092795.jpg               3   \n4  1000092795.jpg               4   \n\n                                             comment  \\\n0  startseq Two young guys with shaggy hair look ...   \n1  startseq Two young White males are outside nea...   \n2  startseq Two men in green shirts are standing ...   \n3  startseq A man in a blue shirt standing in a g...   \n4    startseq Two friends enjoy time together endseq   \n\n                                          image_path  word_length  img_exists  \n0  /kaggle/input/flickr-image-dataset/flickr30k_i...           18        True  \n1  /kaggle/input/flickr-image-dataset/flickr30k_i...           11        True  \n2  /kaggle/input/flickr-image-dataset/flickr30k_i...           12        True  \n3  /kaggle/input/flickr-image-dataset/flickr30k_i...           12        True  \n4  /kaggle/input/flickr-image-dataset/flickr30k_i...            7        True  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>comment_number</th>\n      <th>comment</th>\n      <th>image_path</th>\n      <th>word_length</th>\n      <th>img_exists</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000092795.jpg</td>\n      <td>0</td>\n      <td>startseq Two young guys with shaggy hair look ...</td>\n      <td>/kaggle/input/flickr-image-dataset/flickr30k_i...</td>\n      <td>18</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000092795.jpg</td>\n      <td>1</td>\n      <td>startseq Two young White males are outside nea...</td>\n      <td>/kaggle/input/flickr-image-dataset/flickr30k_i...</td>\n      <td>11</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000092795.jpg</td>\n      <td>2</td>\n      <td>startseq Two men in green shirts are standing ...</td>\n      <td>/kaggle/input/flickr-image-dataset/flickr30k_i...</td>\n      <td>12</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000092795.jpg</td>\n      <td>3</td>\n      <td>startseq A man in a blue shirt standing in a g...</td>\n      <td>/kaggle/input/flickr-image-dataset/flickr30k_i...</td>\n      <td>12</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000092795.jpg</td>\n      <td>4</td>\n      <td>startseq Two friends enjoy time together endseq</td>\n      <td>/kaggle/input/flickr-image-dataset/flickr30k_i...</td>\n      <td>7</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### **For the Sake of COmputation power and time we will train with one caption per image rather than 5 caption per image**","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:06:20.136568Z","iopub.execute_input":"2023-05-16T12:06:20.137221Z","iopub.status.idle":"2023-05-16T12:06:20.143464Z","shell.execute_reply.started":"2023-05-16T12:06:20.137170Z","shell.execute_reply":"2023-05-16T12:06:20.142482Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(158914, 6)"},"metadata":{}}]},{"cell_type":"code","source":"# i randomly chose 2nd comment of all picture you can chose anything bw 0 to 4\ndf= df[(df.comment_number==2) & (df.img_exists==True)]\ndf.shape ","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:06:20.145188Z","iopub.execute_input":"2023-05-16T12:06:20.146018Z","iopub.status.idle":"2023-05-16T12:06:20.176940Z","shell.execute_reply.started":"2023-05-16T12:06:20.145982Z","shell.execute_reply":"2023-05-16T12:06:20.176042Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(31783, 6)"},"metadata":{}}]},{"cell_type":"markdown","source":"now we are just using 1/5 dataset","metadata":{}},{"cell_type":"markdown","source":"# Tokenize","metadata":{}},{"cell_type":"code","source":"\n#tokenizer\ntokenizer = TextVectorization(standardize=preprocess_text)\ntokenizer.adapt(df['comment'])\n\n\nword_to_id = tf.keras.layers.StringLookup(vocabulary=tokenizer.get_vocabulary(), mask_token='', oov_token='[UNK]')\nid_to_word = tf.keras.layers.StringLookup(vocabulary=tokenizer.get_vocabulary(), mask_token='', oov_token='[UNK]', invert=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:06:20.178194Z","iopub.execute_input":"2023-05-16T12:06:20.178740Z","iopub.status.idle":"2023-05-16T12:06:23.181919Z","shell.execute_reply.started":"2023-05-16T12:06:20.178703Z","shell.execute_reply":"2023-05-16T12:06:23.180950Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# load image model\nresnet = tf.keras.applications.ResNet50V2(\n    include_top=False,\n    weights=\"imagenet\",\n    input_tensor=tf.keras.layers.Input(shape=IMG_SHAPE))\n\nresnet.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:06:23.183447Z","iopub.execute_input":"2023-05-16T12:06:23.183799Z","iopub.status.idle":"2023-05-16T12:06:24.759860Z","shell.execute_reply.started":"2023-05-16T12:06:23.183767Z","shell.execute_reply":"2023-05-16T12:06:24.758861Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# making Dataset","metadata":{}},{"cell_type":"code","source":"def preprocess_text(text):\n\n    text = tf.strings.lower(text)\n\n    text = tf.strings.regex_replace(text, r'\\d', '')\n\n    # Remove any punctuations\n    text = tf.strings.regex_replace(text, '[%s]' % re.escape(\n        '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'), '')\n\n    # Remove single characters\n    text = tf.strings.regex_replace(text, r'\\b\\w\\b', '')\n    # Keep space, a to z, and select punctuation.\n    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n    # Add spaces around punctuation.\n    text = tf.strings.regex_replace(text, '[.?!,¿|]', r' \\0 ')\n    # Strip whitespace.\n    text = tf.strings.strip(text)\n\n    return text\n\ndef mapper(x, y, tokenizer):\n    x = load_images_now(x)\n    y = tokenizer(y)\n\n    y_in = y[:-1]\n    y_in =  tf.pad(y_in, [[0, MAX_LEN - tf.shape(y_in)[0]]] , constant_values=0)\n\n    y_out = y[1:]\n    y_out =  tf.pad(y_out, [[0, MAX_LEN - tf.shape(y_out)[0]]], constant_values=0)\n\n    return (x, y_in), y_out\n\n\n@tf.function\ndef load_images_now(x):\n    image_data = tf.io.read_file(x)\n    image_features = tf.image.decode_jpeg(image_data, channels=CHANNELS)\n    image_features = tf.image.resize_with_pad(\n        image_features, target_height=IMG_SIZE, target_width=IMG_SIZE)\n    image_features = tf.keras.applications.resnet.preprocess_input(\n        image_features)\n    image_features = tf.reshape(\n        image_features, (1, IMG_SIZE, IMG_SIZE, CHANNELS))\n    image_features = resnet(image_features)\n    image_features = GlobalAveragePooling2D()(image_features)\n    image_features = tf.squeeze(image_features)\n\n    return image_features\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:06:24.761353Z","iopub.execute_input":"2023-05-16T12:06:24.761737Z","iopub.status.idle":"2023-05-16T12:06:24.774241Z","shell.execute_reply.started":"2023-05-16T12:06:24.761704Z","shell.execute_reply":"2023-05-16T12:06:24.773269Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Creating dataset\nTEST_SIZE = config.TEST_SIZE\nVAL_SIZE =  config.VAL_SIZE\n\ntrain, val = train_test_split(\n    df[['image_path', 'comment']],  test_size=VAL_SIZE, random_state=11)\ntrain, test = train_test_split(\n    train[['image_path', 'comment']],  test_size=TEST_SIZE, random_state=11)\n\n\ntrain_data = tf.data.Dataset.from_tensor_slices((train.image_path, train.comment))\ntest_data = tf.data.Dataset.from_tensor_slices((test.image_path, test.comment))\nval_data = tf.data.Dataset.from_tensor_slices((val.image_path, val.comment))\n\n\ntrain_data = train_data.map(lambda x,y:mapper(x, y, tokenizer)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\ntest_data =   test_data.map(lambda x,y:mapper(x, y, tokenizer)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\nval_data =     val_data.map(lambda x,y:mapper(x, y, tokenizer)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\n# resnet_output_flattened_shape = 8*8*2048\n\nprint(\"Number of training samples: %d\" %\n      tf.data.experimental.cardinality(train_data))\nprint(\"Number of validation samples: %d\" %\n      tf.data.experimental.cardinality(val_data))\nprint(\"Number of test samples: %d\" %\n      tf.data.experimental.cardinality(test_data))\n\nVOCAB_SIZE = tokenizer.vocabulary_size()\nprint(\"Vocabulary size: %d\" % VOCAB_SIZE)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:06:24.775797Z","iopub.execute_input":"2023-05-16T12:06:24.776357Z","iopub.status.idle":"2023-05-16T12:06:26.386393Z","shell.execute_reply.started":"2023-05-16T12:06:24.776325Z","shell.execute_reply":"2023-05-16T12:06:26.385401Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Number of training samples: 3586\nNumber of validation samples: 199\nNumber of test samples: 189\nVocabulary size: 6830\n","output_type":"stream"}]},{"cell_type":"code","source":"train.shape, len(train_data)*8","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:06:26.387886Z","iopub.execute_input":"2023-05-16T12:06:26.388238Z","iopub.status.idle":"2023-05-16T12:06:26.395960Z","shell.execute_reply.started":"2023-05-16T12:06:26.388205Z","shell.execute_reply":"2023-05-16T12:06:26.395035Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"((28683, 2), 28688)"},"metadata":{}}]},{"cell_type":"code","source":"for (img_in, txt_in), txt_out in train_data.take(1):\n    # print(f'{i.numpy().decode():<40} {j.numpy()}')\n    print('x     : ', img_in.shape)\n    print('y_in  : ', txt_in)\n    print('y_out : ', txt_out)\n    print('\\n')\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:06:26.397171Z","iopub.execute_input":"2023-05-16T12:06:26.398072Z","iopub.status.idle":"2023-05-16T12:06:28.461752Z","shell.execute_reply.started":"2023-05-16T12:06:26.398039Z","shell.execute_reply":"2023-05-16T12:06:28.460674Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"x     :  (8, 2048)\ny_in  :  tf.Tensor(\n[[   2   31    8   26    6    5  429   10   65  352  174    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0]\n [   2   45    9    7  228    4  254   16  399   59  297    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0]\n [   2   12    4   87  396  129  536    6   40  163   38   36 1244  128\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0]\n [   2   18  232   12  118   36    5  669   10  223  106    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0]\n [   2    7    9   12  704    4 2116 1738    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0]\n [   2   23    9   22   32   69    4  321  110    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0]\n [   2   15  196   55  511   10  122  100   74    9 2575  590 1611   56\n   323    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0]\n [   2  184   15  402  332   16 1688    5 3695    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0]], shape=(8, 50), dtype=int64)\ny_out :  tf.Tensor(\n[[  31    8   26    6    5  429   10   65  352  174    3    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0]\n [  45    9    7  228    4  254   16  399   59  297    3    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0]\n [  12    4   87  396  129  536    6   40  163   38   36 1244  128    3\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0]\n [  18  232   12  118   36    5  669   10  223  106    3    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0]\n [   7    9   12  704    4 2116 1738    3    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0]\n [  23    9   22   32   69    4  321  110    3    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0]\n [  15  196   55  511   10  122  100   74    9 2575  590 1611   56  323\n     3    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0]\n [ 184   15  402  332   16 1688    5 3695    3    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0]], shape=(8, 50), dtype=int64)\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"\ndef get_model():\n    encoder = LSTM(UNITS, return_sequences=True, return_state=True)\n    decoder = LSTM(UNITS, return_sequences=True)\n\n    embedding = Embedding(\n        input_dim=VOCAB_SIZE,\n        output_dim=EMBEDDING_DIMENSION,\n        mask_zero=True,\n        input_length=MAX_LEN,\n        trainable=True,\n    )\n\n\n\n    image_input = Input(shape=(2048,), name = 'image_input')\n    print('image_input: ',image_input.shape)\n\n    x = Dropout(.3)(image_input)\n    print('enc dropout: ',x.shape)\n    \n    x = Dense(MAX_LEN*UNITS, activation = 'relu', kernel_initializer = 'glorot_uniform' )(x)\n    print('Dense: ',x.shape)\n    \n    x = tf.reshape(x, (-1, MAX_LEN, UNITS))\n    print('reshape: ',x.shape)\n\n\n    txt_input = Input(shape=(MAX_LEN,), name = 'text_input')\n    print('txt_input: ',txt_input.shape)\n    \n    i = embedding(txt_input)\n    print('text_embedding: ',i.shape)\n    \n    i, j, k = encoder(i)\n    print('encoder output: ',i.shape)\n    \n    i = Dropout(.3)(i)\n    print('enc dropout: ',i.shape)\n    \n    i = decoder(i, initial_state=[j, k])\n    print('decoder output: ',i.shape)\n    \n    i = Dropout(.3)(i)\n    print('decoder dropout: ',i.shape)\n\n    l = Attention()([x, i])\n    print('attention: ',l.shape)\n\n    m = Concatenate()([i, l])\n    print('concat: ', m.shape)\n\n    m = Dropout(.3)(m)\n    print('concat dropout: ',m.shape)\n\n    m = Dense(MAX_LEN*UNITS)(m)\n    print('Dense1: ', m.shape)\n\n\n    m = Dense(VOCAB_SIZE)(m)\n    print('Dense3_final: ', m.shape)\n    return Model(inputs=[image_input, txt_input], outputs=m)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:06:28.463394Z","iopub.execute_input":"2023-05-16T12:06:28.464208Z","iopub.status.idle":"2023-05-16T12:06:28.477043Z","shell.execute_reply.started":"2023-05-16T12:06:28.464173Z","shell.execute_reply":"2023-05-16T12:06:28.476128Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"model = get_model()\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:06:28.478247Z","iopub.execute_input":"2023-05-16T12:06:28.479119Z","iopub.status.idle":"2023-05-16T12:06:30.259710Z","shell.execute_reply.started":"2023-05-16T12:06:28.479087Z","shell.execute_reply":"2023-05-16T12:06:30.258937Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"image_input:  (None, 2048)\nenc dropout:  (None, 2048)\nDense:  (None, 800)\nreshape:  (None, 50, 16)\ntxt_input:  (None, 50)\ntext_embedding:  (None, 50, 50)\nencoder output:  (None, 50, 16)\nenc dropout:  (None, 50, 16)\ndecoder output:  (None, 50, 16)\ndecoder dropout:  (None, 50, 16)\nattention:  (None, 50, 16)\nconcat:  (None, 50, 32)\nconcat dropout:  (None, 50, 32)\nDense1:  (None, 50, 800)\nDense3_final:  (None, 50, 6830)\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n text_input (InputLayer)        [(None, 50)]         0           []                               \n                                                                                                  \n embedding (Embedding)          (None, 50, 50)       341500      ['text_input[0][0]']             \n                                                                                                  \n lstm (LSTM)                    [(None, 50, 16),     4288        ['embedding[0][0]']              \n                                 (None, 16),                                                      \n                                 (None, 16)]                                                      \n                                                                                                  \n image_input (InputLayer)       [(None, 2048)]       0           []                               \n                                                                                                  \n dropout_1 (Dropout)            (None, 50, 16)       0           ['lstm[0][0]']                   \n                                                                                                  \n dropout (Dropout)              (None, 2048)         0           ['image_input[0][0]']            \n                                                                                                  \n lstm_1 (LSTM)                  (None, 50, 16)       2112        ['dropout_1[0][0]',              \n                                                                  'lstm[0][1]',                   \n                                                                  'lstm[0][2]']                   \n                                                                                                  \n dense (Dense)                  (None, 800)          1639200     ['dropout[0][0]']                \n                                                                                                  \n dropout_2 (Dropout)            (None, 50, 16)       0           ['lstm_1[0][0]']                 \n                                                                                                  \n tf.reshape (TFOpLambda)        (None, 50, 16)       0           ['dense[0][0]']                  \n                                                                                                  \n attention (Attention)          (None, 50, 16)       0           ['tf.reshape[0][0]',             \n                                                                  'dropout_2[0][0]']              \n                                                                                                  \n concatenate (Concatenate)      (None, 50, 32)       0           ['dropout_2[0][0]',              \n                                                                  'attention[0][0]']              \n                                                                                                  \n dropout_3 (Dropout)            (None, 50, 32)       0           ['concatenate[0][0]']            \n                                                                                                  \n dense_1 (Dense)                (None, 50, 800)      26400       ['dropout_3[0][0]']              \n                                                                                                  \n dense_2 (Dense)                (None, 50, 6830)     5470830     ['dense_1[0][0]']                \n                                                                                                  \n==================================================================================================\nTotal params: 7,484,330\nTrainable params: 7,484,330\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef masked_loss(y_true, y_pred):\n    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n        reduction='none')\n    loss = loss_fn(y_true, y_pred)\n\n    mask = tf.cast(y_true != 0, loss.dtype)\n    loss *= mask\n\n    return tf.reduce_sum(loss)/tf.reduce_sum(mask)\n\ndef masked_acc(y_true, y_pred):\n    y_pred = tf.argmax(y_pred, axis=-1)\n    y_pred = tf.cast(y_pred, y_true.dtype)\n\n    matchh = tf.cast(y_true == y_pred, tf.float32)\n    mask = tf.cast(y_true != 0, tf.float32)\n\n    return tf.reduce_sum(matchh)/tf.reduce_sum(mask)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:06:30.260746Z","iopub.execute_input":"2023-05-16T12:06:30.261072Z","iopub.status.idle":"2023-05-16T12:06:30.272870Z","shell.execute_reply.started":"2023-05-16T12:06:30.261038Z","shell.execute_reply":"2023-05-16T12:06:30.272011Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"print(LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:06:30.279031Z","iopub.execute_input":"2023-05-16T12:06:30.279597Z","iopub.status.idle":"2023-05-16T12:06:30.290415Z","shell.execute_reply.started":"2023-05-16T12:06:30.279557Z","shell.execute_reply":"2023-05-16T12:06:30.289410Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"0.01\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n              loss=masked_loss,\n              metrics=[masked_acc])\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:06:30.291609Z","iopub.execute_input":"2023-05-16T12:06:30.292493Z","iopub.status.idle":"2023-05-16T12:06:30.315289Z","shell.execute_reply.started":"2023-05-16T12:06:30.292460Z","shell.execute_reply":"2023-05-16T12:06:30.314271Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"os.makedirs('log', exist_ok=True)\ncsv_logger = CSVLogger('./log/training.log')\ntb_callback = tf.keras.callbacks.TensorBoard('./logs', update_freq=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:06:30.316758Z","iopub.execute_input":"2023-05-16T12:06:30.317107Z","iopub.status.idle":"2023-05-16T12:06:30.322863Z","shell.execute_reply.started":"2023-05-16T12:06:30.317075Z","shell.execute_reply":"2023-05-16T12:06:30.321793Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 60\n\nprint(len(train_data) // EPOCHS, len(val_data) // EPOCHS)\n\nsteps_per_epoch = int(1*(len(train_data) / EPOCHS))\nvalidation_steps =  int(1*(len(val_data) / EPOCHS))\nprint(steps_per_epoch, validation_steps)\n\nsteps_per_epoch = 150\nvalidation_steps = 2\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:06:30.324459Z","iopub.execute_input":"2023-05-16T12:06:30.324788Z","iopub.status.idle":"2023-05-16T12:06:30.337409Z","shell.execute_reply.started":"2023-05-16T12:06:30.324758Z","shell.execute_reply":"2023-05-16T12:06:30.336353Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"59 3\n59 3\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## model.fit","metadata":{}},{"cell_type":"code","source":"history = model.fit(train_data.repeat(),\n                    epochs=EPOCHS,\n                    validation_data=val_data,\n                    steps_per_epoch=steps_per_epoch,\n                    validation_steps=validation_steps,\n                    callbacks=[\n                        # decay_callback,\n                        csv_logger, create_model_checkpoint(model_name = 'capgen', save_dir = 'checkpoints', monitor = 'masked_acc')\n                                ]\n                    )","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:06:30.339203Z","iopub.execute_input":"2023-05-16T12:06:30.339905Z","iopub.status.idle":"2023-05-16T12:16:31.719906Z","shell.execute_reply.started":"2023-05-16T12:06:30.339874Z","shell.execute_reply":"2023-05-16T12:16:31.715663Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Epoch 1/60\n150/150 [==============================] - 198s 1s/step - loss: 9.9848 - masked_acc: 0.0076 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\nEpoch 2/60\n150/150 [==============================] - 146s 976ms/step - loss: 8.8291 - masked_acc: 8.4720e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\nEpoch 3/60\n150/150 [==============================] - 152s 1s/step - loss: 8.8291 - masked_acc: 5.3447e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\nEpoch 4/60\n102/150 [===================>..........] - ETA: 48s - loss: 8.8291 - masked_acc: 3.3769e-04","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;66;43;03m# decay_callback,\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcsv_logger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_model_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapgen\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcheckpoints\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmasked_acc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"from datetime import datetime","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:16:31.721165Z","iopub.status.idle":"2023-05-16T12:16:31.721653Z","shell.execute_reply.started":"2023-05-16T12:16:31.721406Z","shell.execute_reply":"2023-05-16T12:16:31.721428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(f'saved_model/{datetime.now()}-{EPOCH}.h5')","metadata":{"execution":{"iopub.status.busy":"2023-05-16T12:16:31.722807Z","iopub.status.idle":"2023-05-16T12:16:31.724033Z","shell.execute_reply.started":"2023-05-16T12:16:31.723779Z","shell.execute_reply":"2023-05-16T12:16:31.723808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}