{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system('git clone https://github.com/tikendraw/caption-generator.git -q')\n",
    "# os.chdir('caption-generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 17:19:07.579173: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-21 17:19:08.884768: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-05-21 17:19:11.487864: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-21 17:19:11.532817: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-21 17:19:11.533030: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-21 17:19:11.534068: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-21 17:19:11.534242: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-21 17:19:11.534384: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-21 17:19:12.350340: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-21 17:19:12.350582: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-21 17:19:12.350739: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-21 17:19:12.350854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2184 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random, math\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import shutil\n",
    "from zipfile import ZipFile\n",
    "import datetime\n",
    "import sys\n",
    "from functools import cache\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import regex as re\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocessing\n",
    "from tensorflow.keras.layers import (\n",
    "    TextVectorization, Embedding, LSTM, GRU, Bidirectional, TimeDistributed, Dense, Attention, MultiHeadAttention, Flatten, Dropout,\n",
    "    Concatenate, Activation, GlobalAveragePooling2D\n",
    "    )\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Input, Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import array_to_img, img_to_array\n",
    "import string\n",
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, TensorBoard\n",
    "from model import LearningRateDecayCallback, get_model, masked_acc, masked_loss\n",
    "from preprocessing import preprocess_text, embedding_matrix_creater, mapper, clean_words\n",
    "from utils import create_model_checkpoint\n",
    "\n",
    "from config import config\n",
    "\n",
    "from get_data import download_dataset\n",
    "from funcyou.dataset import download_kaggle_dataset\n",
    "import polars as pl\n",
    "from preprocess_data import clean_the_df\n",
    "from funcyou.utils import printt, dir_walk\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import regex as re\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_path = './config.yaml'\n",
    "\n",
    "# Read the config file \n",
    "with open(config_file_path, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "\n",
    "RAW_CAPTION_FILE                        = Path(config['raw_caption_file'])\n",
    "CAPTION_FILE                            = Path(config['caption_file'])\n",
    "IMAGE_DIR                               = Path(config['image_dir'])\n",
    "IMG_SIZE                                = config['img_size']\n",
    "CHANNELS                                = config['channels']\n",
    "IMG_SHAPE                               = config['img_shape']\n",
    "MAX_LEN                                 = config['max_len']\n",
    "BATCH_SIZE                              = config['batch_size']\n",
    "EPOCHS                                  = config['epochs']\n",
    "LEARNING_RATE                           = config['learning_rate']\n",
    "UNITS                                   = config['units']\n",
    "TEST_SIZE                               = config['test_size']\n",
    "VALIDATION_SIZE                         = config['val_size']\n",
    "EMBEDDING_DIMENSION                     = config['embedding_dimension']\n",
    "GLOVE_PATH                              = config['glove_path']\n",
    "D_MODEL                                 = config['d_model']\n",
    "NUM_HEADS                               = config['num_heads']    \n",
    "NUM_LAYERS                               = config['num_layers']    \n",
    "PATCH_SIZE                              = config['patch_size']    \n",
    "TRANSFORMER_LAYERS                      = config['transformer_layers']        \n",
    "\n",
    "NUM_PATCHES = (IMG_SIZE // PATCH_SIZE) ** 2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      RAW_CAPTION_FILE=PosixPath('input/flickr30k/results.csv')\n",
      "CAPTION_FILE=PosixPath('input/flickr30k/results_cleaned.csv')\n",
      "IMAGE_DIR=PosixPath('input/flickr30k/images')\n",
      "IMG_SIZE=256\n",
      "CHANNELS=3\n",
      "IMG_SHAPE=[256, 256, 3]\n",
      "MAX_LEN=50\n",
      "BATCH_SIZE=8\n",
      "EPOCHS=10\n",
      "LEARNING_RATE=0.01\n",
      "UNITS=16\n",
      "TEST_SIZE=0.05\n",
      "VALIDATION_SIZE=0.05\n",
      "EMBEDDING_DIMENSION=50\n",
      "GLOVE_PATH='embedding/glove.6B.50d.zip'\n",
      "D_MODEL=128\n",
      "NUM_HEADS=4\n",
      "NUM_LAYERS=4\n",
      "PATCH_SIZE=42\n",
      "TRANSFORMER_LAYERS=8\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "{      RAW_CAPTION_FILE=}\n",
    "{CAPTION_FILE=}\n",
    "{IMAGE_DIR=}\n",
    "{IMG_SIZE=}\n",
    "{CHANNELS=}\n",
    "{IMG_SHAPE=}\n",
    "{MAX_LEN=}\n",
    "{BATCH_SIZE=}\n",
    "{EPOCHS=}\n",
    "{LEARNING_RATE=}\n",
    "{UNITS=}\n",
    "{TEST_SIZE=}\n",
    "{VALIDATION_SIZE=}\n",
    "{EMBEDDING_DIMENSION=}\n",
    "{GLOVE_PATH=}\n",
    "{D_MODEL=}\n",
    "{NUM_HEADS=}\n",
    "{NUM_LAYERS=}\n",
    "{PATCH_SIZE=}\n",
    "{TRANSFORMER_LAYERS=}\n",
    "      ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 8\n",
    "IMG_SHAPE = (128,128,3)\n",
    "D_MODEL = 32\n",
    "MAX_LEN = 30\n",
    "PATCH_SIZE = 32\n",
    "NUM_PATCHES = (IMG_SIZE // PATCH_SIZE) ** 2\n",
    "NUM_PATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN = 'startseq'\n",
    "END_TOKEN = 'endseq'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curating Dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Null/Bad Entries removed\n",
    "2. Columns names stripped and lowered\n",
    "3. Low frequency word (<5) has been removed \n",
    "4. Added start and end tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are keeping words in comments which atleast has occured  5 times( there are unnecessary word which we don't want) \n",
    "there are ~12000 words that doesn't even gets repeated 5 times in 150000 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_the_df(RAW_CAPTION_FILE, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>image_name</th><th>comment_number</th><th>comment</th><th>no_rare_words</th><th>sent_len</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>bool</td><td>i64</td></tr></thead><tbody><tr><td>&quot;1000092795.jpg…</td><td>0</td><td>&quot;startseq  Two …</td><td>true</td><td>18</td></tr><tr><td>&quot;1000092795.jpg…</td><td>1</td><td>&quot;startseq  Two …</td><td>true</td><td>11</td></tr><tr><td>&quot;1000092795.jpg…</td><td>2</td><td>&quot;startseq  Two …</td><td>true</td><td>12</td></tr><tr><td>&quot;1000092795.jpg…</td><td>3</td><td>&quot;startseq  A ma…</td><td>true</td><td>12</td></tr><tr><td>&quot;1000092795.jpg…</td><td>4</td><td>&quot;startseq  Two …</td><td>true</td><td>7</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌────────────────┬────────────────┬───────────────────────────────────┬───────────────┬──────────┐\n",
       "│ image_name     ┆ comment_number ┆ comment                           ┆ no_rare_words ┆ sent_len │\n",
       "│ ---            ┆ ---            ┆ ---                               ┆ ---           ┆ ---      │\n",
       "│ str            ┆ i64            ┆ str                               ┆ bool          ┆ i64      │\n",
       "╞════════════════╪════════════════╪═══════════════════════════════════╪═══════════════╪══════════╡\n",
       "│ 1000092795.jpg ┆ 0              ┆ startseq  Two young guys with sh… ┆ true          ┆ 18       │\n",
       "│ 1000092795.jpg ┆ 1              ┆ startseq  Two young White males … ┆ true          ┆ 11       │\n",
       "│ 1000092795.jpg ┆ 2              ┆ startseq  Two men in green shirt… ┆ true          ┆ 12       │\n",
       "│ 1000092795.jpg ┆ 3              ┆ startseq  A man in a blue shirt … ┆ true          ┆ 12       │\n",
       "│ 1000092795.jpg ┆ 4              ┆ startseq  Two friends enjoy time… ┆ true          ┆ 7        │\n",
       "└────────────────┴────────────────┴───────────────────────────────────┴───────────────┴──────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_csv('cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete before this code \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned.csv')\n",
    "\n",
    "try:\n",
    "    df.drop('Unnamed: 0',axis=1, inplace=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158914, 5)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 158914 entries, 0 to 158913\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   image_name      158914 non-null  object\n",
      " 1   comment_number  158914 non-null  int64 \n",
      " 2   comment         158914 non-null  object\n",
      " 3   no_rare_words   158914 non-null  bool  \n",
      " 4   sent_len        158914 non-null  int64 \n",
      "dtypes: bool(1), int64(2), object(2)\n",
      "memory usage: 5.0+ MB\n",
      "None\n",
      "['image_name', 'comment_number', 'comment', 'no_rare_words', 'sent_len']\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.to_pandas().info())\n",
    "print(df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **For the Sake of COmputation power and time we will train with one caption per image rather than 5 caption per image**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding median sentence length for all class of comment numbers, to ensure that our MAX_LEN covers all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>image_name</th><th>comment_number</th><th>comment</th><th>no_rare_words</th><th>sent_len</th><th>image_path</th><th>img_exists</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>bool</td><td>i64</td><td>str</td><td>bool</td></tr></thead><tbody><tr><td>&quot;1000092795.jpg…</td><td>0</td><td>&quot;startseq  Two …</td><td>true</td><td>18</td><td>&quot;input/flickr30…</td><td>true</td></tr><tr><td>&quot;1000092795.jpg…</td><td>1</td><td>&quot;startseq  Two …</td><td>true</td><td>11</td><td>&quot;input/flickr30…</td><td>true</td></tr><tr><td>&quot;1000092795.jpg…</td><td>2</td><td>&quot;startseq  Two …</td><td>true</td><td>12</td><td>&quot;input/flickr30…</td><td>true</td></tr><tr><td>&quot;1000092795.jpg…</td><td>3</td><td>&quot;startseq  A ma…</td><td>true</td><td>12</td><td>&quot;input/flickr30…</td><td>true</td></tr><tr><td>&quot;1000092795.jpg…</td><td>4</td><td>&quot;startseq  Two …</td><td>true</td><td>7</td><td>&quot;input/flickr30…</td><td>true</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌──────────────┬──────────────┬──────────────┬──────────────┬──────────┬──────────────┬────────────┐\n",
       "│ image_name   ┆ comment_numb ┆ comment      ┆ no_rare_word ┆ sent_len ┆ image_path   ┆ img_exists │\n",
       "│ ---          ┆ er           ┆ ---          ┆ s            ┆ ---      ┆ ---          ┆ ---        │\n",
       "│ str          ┆ ---          ┆ str          ┆ ---          ┆ i64      ┆ str          ┆ bool       │\n",
       "│              ┆ i64          ┆              ┆ bool         ┆          ┆              ┆            │\n",
       "╞══════════════╪══════════════╪══════════════╪══════════════╪══════════╪══════════════╪════════════╡\n",
       "│ 1000092795.j ┆ 0            ┆ startseq     ┆ true         ┆ 18       ┆ input/flickr ┆ true       │\n",
       "│ pg           ┆              ┆ Two young    ┆              ┆          ┆ 30k/images/1 ┆            │\n",
       "│              ┆              ┆ guys with    ┆              ┆          ┆ 00009279…    ┆            │\n",
       "│              ┆              ┆ sh…          ┆              ┆          ┆              ┆            │\n",
       "│ 1000092795.j ┆ 1            ┆ startseq     ┆ true         ┆ 11       ┆ input/flickr ┆ true       │\n",
       "│ pg           ┆              ┆ Two young    ┆              ┆          ┆ 30k/images/1 ┆            │\n",
       "│              ┆              ┆ White males  ┆              ┆          ┆ 00009279…    ┆            │\n",
       "│              ┆              ┆ …            ┆              ┆          ┆              ┆            │\n",
       "│ 1000092795.j ┆ 2            ┆ startseq     ┆ true         ┆ 12       ┆ input/flickr ┆ true       │\n",
       "│ pg           ┆              ┆ Two men in   ┆              ┆          ┆ 30k/images/1 ┆            │\n",
       "│              ┆              ┆ green shirt… ┆              ┆          ┆ 00009279…    ┆            │\n",
       "│ 1000092795.j ┆ 3            ┆ startseq  A  ┆ true         ┆ 12       ┆ input/flickr ┆ true       │\n",
       "│ pg           ┆              ┆ man in a     ┆              ┆          ┆ 30k/images/1 ┆            │\n",
       "│              ┆              ┆ blue shirt … ┆              ┆          ┆ 00009279…    ┆            │\n",
       "│ 1000092795.j ┆ 4            ┆ startseq     ┆ true         ┆ 7        ┆ input/flickr ┆ true       │\n",
       "│ pg           ┆              ┆ Two friends  ┆              ┆          ┆ 30k/images/1 ┆            │\n",
       "│              ┆              ┆ enjoy time…  ┆              ┆          ┆ 00009279…    ┆            │\n",
       "└──────────────┴──────────────┴──────────────┴──────────────┴──────────┴──────────────┴────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.with_columns([\n",
    "    pl.col(\"image_name\").apply(lambda x: str(IMAGE_DIR / x) ).alias('image_path') \n",
    "])\n",
    "\n",
    "df = df.with_columns([\n",
    "    pl.col(\"image_path\").apply(lambda x: os.path.isfile(x)).alias('img_exists') \n",
    "])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>comment_number</th><th>mean</th><th>median</th><th>min</th><th>max</th><th>count</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>19.871315</td><td>19.0</td><td>6</td><td>79</td><td>31783</td></tr><tr><td>1</td><td>15.859327</td><td>15.0</td><td>6</td><td>41</td><td>31783</td></tr><tr><td>2</td><td>13.602869</td><td>13.0</td><td>4</td><td>34</td><td>31783</td></tr><tr><td>3</td><td>11.771639</td><td>11.0</td><td>4</td><td>36</td><td>31783</td></tr><tr><td>4</td><td>9.871437</td><td>10.0</td><td>3</td><td>38</td><td>31782</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 6)\n",
       "┌────────────────┬───────────┬────────┬─────┬─────┬───────┐\n",
       "│ comment_number ┆ mean      ┆ median ┆ min ┆ max ┆ count │\n",
       "│ ---            ┆ ---       ┆ ---    ┆ --- ┆ --- ┆ ---   │\n",
       "│ i64            ┆ f64       ┆ f64    ┆ i64 ┆ i64 ┆ u32   │\n",
       "╞════════════════╪═══════════╪════════╪═════╪═════╪═══════╡\n",
       "│ 0              ┆ 19.871315 ┆ 19.0   ┆ 6   ┆ 79  ┆ 31783 │\n",
       "│ 1              ┆ 15.859327 ┆ 15.0   ┆ 6   ┆ 41  ┆ 31783 │\n",
       "│ 2              ┆ 13.602869 ┆ 13.0   ┆ 4   ┆ 34  ┆ 31783 │\n",
       "│ 3              ┆ 11.771639 ┆ 11.0   ┆ 4   ┆ 36  ┆ 31783 │\n",
       "│ 4              ┆ 9.871437  ┆ 10.0   ┆ 3   ┆ 38  ┆ 31782 │\n",
       "└────────────────┴───────────┴────────┴─────┴─────┴───────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by a categorical column\n",
    "grouped = df.groupby('comment_number')\n",
    "\n",
    "# Apply aggregation functions on numerical columns\n",
    "aggregated = grouped.agg(\n",
    "    pl.col('sent_len').mean().alias('mean'), \n",
    "    pl.col('sent_len').median().alias('median'), \n",
    "    pl.col('sent_len').min().alias('min'), \n",
    "    pl.col('sent_len').max().alias('max'), \n",
    "    pl.col('sent_len').count().alias('count')\n",
    ")\n",
    "aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31783, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i randomly chose 2nd comment of all picture you can chose anything bw 0 to 4\n",
    "df = df.filter(\n",
    "    (pl.col(\"comment_number\") == 1) & (pl.col(\"img_exists\") == True) & (pl.col(\"sent_len\") < 51)\n",
    ")\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we are just using 1/5 dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "\n",
    "    text = tf.strings.lower(text)\n",
    "\n",
    "    text = tf.strings.regex_replace(text, r'\\d', '')\n",
    "\n",
    "    # Remove any punctuations\n",
    "    text = tf.strings.regex_replace(text, '[%s]' % re.escape(\n",
    "        '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'), '')\n",
    "\n",
    "    # Remove single characters\n",
    "    text = tf.strings.regex_replace(text, r'\\b\\w\\b', '')\n",
    "    # Keep space, a to z, and select punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
    "    # Add spaces around punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[.?!,¿|]', r' \\0 ')\n",
    "    # Strip whitespace.\n",
    "    text = tf.strings.strip(text)\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#tokenizer\n",
    "tokenizer = TextVectorization(standardize=preprocess_text)\n",
    "tokenizer.adapt(df['comment'].to_list())\n",
    "\n",
    "\n",
    "word_to_id = tf.keras.layers.StringLookup(vocabulary=tokenizer.get_vocabulary(), mask_token='', oov_token='[UNK]')\n",
    "id_to_word = tf.keras.layers.StringLookup(vocabulary=tokenizer.get_vocabulary(), mask_token='', oov_token='[UNK]', invert=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# making Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mapper(x, y, tokenizer):\n",
    "    x = load_images_now(x)\n",
    "    y = tokenizer(y)\n",
    "\n",
    "    y_in = y[:-1]\n",
    "    y_in =  tf.pad(y_in, [[0, MAX_LEN - tf.shape(y_in)[0]]] , constant_values=0)\n",
    "\n",
    "    y_out = y[1:]\n",
    "    y_out =  tf.pad(y_out, [[0, MAX_LEN - tf.shape(y_out)[0]]], constant_values=0)\n",
    "\n",
    "    return (x, y_in), y_out\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def load_images_now(x):\n",
    "    image_data = tf.io.read_file(x)\n",
    "    image_features = tf.image.decode_jpeg(image_data, channels=CHANNELS)\n",
    "    image_features = tf.image.resize_with_pad(\n",
    "        image_features, target_height=IMG_SIZE, target_width=IMG_SIZE)\n",
    "    return image_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_filepath = random.choices(df['image_path'].to_list(), k=1)[0]\n",
    "p_image = load_images_now(str(random_image_filepath))\n",
    "array_to_img(p_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 17:19:26.047190: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'args_0' with dtype string\n",
      "\t [[{{node args_0}}]]\n",
      "2023-05-21 17:19:26.119187: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'args_0' with dtype string\n",
      "\t [[{{node args_0}}]]\n",
      "2023-05-21 17:19:26.201410: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'args_0' with dtype string\n",
      "\t [[{{node args_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 3586\n",
      "Number of validation samples: 199\n",
      "Number of test samples: 189\n",
      "Vocabulary size: 7102\n"
     ]
    }
   ],
   "source": [
    "# Creating dataset\n",
    "TEST_SIZE = config['test_size']\n",
    "VAL_SIZE =  config['val_size']\n",
    "\n",
    "train, val = train_test_split(\n",
    "    df[['image_path', 'comment']],  test_size=VAL_SIZE, random_state=11)\n",
    "train, test = train_test_split(\n",
    "    train[['image_path', 'comment']],  test_size=TEST_SIZE, random_state=11)\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((train['image_path'].to_list(), train['comment'].to_list()))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((test['image_path'].to_list(), test['comment'].to_list()))\n",
    "val_data = tf.data.Dataset.from_tensor_slices((val['image_path'].to_list(), val['comment'].to_list()))\n",
    "\n",
    "\n",
    "train_data = train_data.map(lambda x,y:mapper(x, y, tokenizer)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_data =   test_data.map(lambda x,y:mapper(x, y, tokenizer)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_data =     val_data.map(lambda x,y:mapper(x, y, tokenizer)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# resnet_output_flattened_shape = 8*8*2048\n",
    "\n",
    "print(\"Number of training samples: %d\" %\n",
    "      tf.data.experimental.cardinality(train_data))\n",
    "print(\"Number of validation samples: %d\" %\n",
    "      tf.data.experimental.cardinality(val_data))\n",
    "print(\"Number of test samples: %d\" %\n",
    "      tf.data.experimental.cardinality(test_data))\n",
    "\n",
    "VOCAB_SIZE = tokenizer.vocabulary_size()\n",
    "print(\"Vocabulary size: %d\" % VOCAB_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28683, 2), 28688)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, len(train_data)*BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x     :  (8, 128, 128, 3)\n",
      "y_in.shape(one batch)  :  (8, 30)\n",
      "y_in  :  tf.Tensor(\n",
      "[   2 1710   31    8  580    6    4  192   11   56    9  326  251    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0], shape=(30,), dtype=int64)\n",
      "y_out.shape(one batch)  :  (8, 30)\n",
      "y_out :  tf.Tensor(\n",
      "[1710   31    8  580    6    4  192   11   56    9  326  251    3    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0], shape=(30,), dtype=int64)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 17:19:26.324336: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype string\n",
      "\t [[{{node Placeholder/_5}}]]\n"
     ]
    }
   ],
   "source": [
    "for (img_in, txt_in), txt_out in train_data.take(1):\n",
    "    # print(f'{i.numpy().decode():<40} {j.numpy()}')\n",
    "    print('x     : ', img_in.shape)\n",
    "    print('y_in.shape(one batch)  : ', txt_in.shape)\n",
    "    \n",
    "    print('y_in  : ', txt_in[0])\n",
    "    \n",
    "    print('y_out.shape(one batch)  : ', txt_out.shape)\n",
    "    print('y_out : ', txt_out[0])\n",
    "    print('\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFF = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import CaptionGenerator, Encoder, Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder( NUM_LAYERS, D_MODEL, NUM_HEADS, DFF, PATCH_SIZE, NUM_PATCHES, dropout_rate=0.1)\n",
    "dec = Decoder( NUM_LAYERS, D_MODEL, NUM_HEADS, DFF, VOCAB_SIZE, dropout_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CaptionGenerator(NUM_LAYERS, D_MODEL, NUM_HEADS, DFF, VOCAB_SIZE, PATCH_SIZE, NUM_PATCHES, dropout_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([8, 128, 128, 3]), TensorShape([8, 30]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_in.shape, txt_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ee = enc(img_in)\n",
    "# ee.shape  #([batch_size, num_patches, d_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dd = dec(x = txt_in, context = ee)\n",
    "dd.shape   #([batch_size, max_len, d_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorShape([16])\n",
      "attn_output:  TensorShape([8, 16, 32])\n",
      "concat:  TensorShape([8, 16, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 16:36:03.522897: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.1.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-05-21 16:36:03.523940: W ./tensorflow/compiler/xla/stream_executor/stream.h:1583] attempting to perform DNN operation using StreamExecutor without DNN support\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Exception encountered when calling layer 'layer_normalization_32' (type LayerNormalization).\n\n{{function_node __wrapped__FusedBatchNormV3_device_/job:localhost/replica:0/task:0/device:GPU:0}} cuDNN launch failure : input shape ([1,128,32,1]) [Op:FusedBatchNormV3]\n\nCall arguments received by layer 'layer_normalization_32' (type LayerNormalization):\n  • inputs=tf.Tensor(shape=(8, 16, 32), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[39m=\u001b[39m model((img_in, txt_in))\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_new/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/cproject/caption-generator/transformer.py:369\u001b[0m, in \u001b[0;36mCaptionGenerator.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs):  \u001b[39m# sourcery skip: inline-immediately-returned-variable, use-contextlib-suppress\u001b[39;00m\n\u001b[1;32m    367\u001b[0m     img, txt  \u001b[39m=\u001b[39m inputs\n\u001b[0;32m--> 369\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(img)  \u001b[39m# (batch_size, context_len, d_model)\u001b[39;00m\n\u001b[1;32m    371\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(x\u001b[39m=\u001b[39mtxt, context\u001b[39m=\u001b[39mimg)  \u001b[39m# (batch_size, target_len, d_model)\u001b[39;00m\n\u001b[1;32m    373\u001b[0m     \u001b[39m# Final linear layer output.\u001b[39;00m\n",
      "File \u001b[0;32m~/cproject/caption-generator/transformer.py:264\u001b[0m, in \u001b[0;36mEncoder.call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    261\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x)\n\u001b[1;32m    263\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers):\n\u001b[0;32m--> 264\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menc_layers[i](x)\n\u001b[1;32m    266\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/cproject/caption-generator/transformer.py:224\u001b[0m, in \u001b[0;36mEncoderLayer.call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 224\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attention(x)\n\u001b[1;32m    225\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mffn(x)\n\u001b[1;32m    226\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/cproject/caption-generator/transformer.py:175\u001b[0m, in \u001b[0;36mGlobalSelfAttention.call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    172\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd([x, attn_output])\n\u001b[1;32m    173\u001b[0m tf\u001b[39m.\u001b[39mprint(\u001b[39m'\u001b[39m\u001b[39mconcat: \u001b[39m\u001b[39m'\u001b[39m,x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m--> 175\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayernorm(x)\n\u001b[1;32m    176\u001b[0m tf\u001b[39m.\u001b[39mprint(\u001b[39m'\u001b[39m\u001b[39mlayernorm: \u001b[39m\u001b[39m'\u001b[39m,x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    178\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[0;31mInternalError\u001b[0m: Exception encountered when calling layer 'layer_normalization_32' (type LayerNormalization).\n\n{{function_node __wrapped__FusedBatchNormV3_device_/job:localhost/replica:0/task:0/device:GPU:0}} cuDNN launch failure : input shape ([1,128,32,1]) [Op:FusedBatchNormV3]\n\nCall arguments received by layer 'layer_normalization_32' (type LayerNormalization):\n  • inputs=tf.Tensor(shape=(8, 16, 32), dtype=float32)"
     ]
    }
   ],
   "source": [
    "output = model((img_in, txt_in))\n",
    "output.shape  #([batch_size, max_len, vocab_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def masked_loss(y_true, y_pred):\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        reduction='none')\n",
    "    loss = loss_fn(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(y_true != 0, loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "\n",
    "def masked_acc(y_true, y_pred):\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
    "\n",
    "    matchh = tf.cast(y_true == y_pred, tf.float32)\n",
    "    mask = tf.cast(y_true != 0, tf.float32)\n",
    "\n",
    "    return tf.reduce_sum(matchh)/tf.reduce_sum(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    }
   ],
   "source": [
    "print(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "              loss=masked_loss,\n",
    "              metrics=[masked_acc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x79b6ee33bb20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.load_weights(f'model_weights/best_so_far/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('log', exist_ok=True)\n",
    "csv_logger = CSVLogger('./log/training.log',append=True )\n",
    "tb_callback = tf.keras.callbacks.TensorBoard('./logs', update_freq=1)\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0\n",
      "20 1\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 360\n",
    "print(len(train_data) // EPOCHS, len(val_data) // EPOCHS)\n",
    "\n",
    "# steps_per_epoch = int(1*(len(train_data) / EPOCHS))\n",
    "# validation_steps =  int(1*(len(val_data) / EPOCHS))\n",
    "# print(steps_per_epoch, validation_steps)\n",
    "\n",
    "steps_per_epoch = 20\n",
    "validation_steps = 1\n",
    "print(steps_per_epoch, validation_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3586, 199, 189)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'expected_loss': 8.829079952564836, 'expected_acc': 0.00014641288433382137}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "{\"expected_loss\": np.log(VOCAB_SIZE),\n",
    " \"expected_acc\": 1/VOCAB_SIZE}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/360\n",
      "20/20 [==============================] - 120s 5s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 2/360\n",
      "20/20 [==============================] - 63s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 3/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 4/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 5/360\n",
      "20/20 [==============================] - 71s 4s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 6/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 7/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8315 - masked_acc: 5.6306e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 8/360\n",
      "20/20 [==============================] - 108s 6s/step - loss: 8.8291 - masked_acc: 0.0023 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 9/360\n",
      "20/20 [==============================] - 51s 3s/step - loss: 8.8291 - masked_acc: 5.6948e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 10/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8320 - masked_acc: 5.9312e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 11/360\n",
      "20/20 [==============================] - 69s 4s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 12/360\n",
      "20/20 [==============================] - 69s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 13/360\n",
      "20/20 [==============================] - 73s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 14/360\n",
      "20/20 [==============================] - 70s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 15/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 16/360\n",
      "20/20 [==============================] - 71s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 17/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 5.6948e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 18/360\n",
      "20/20 [==============================] - 72s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 19/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8291 - masked_acc: 5.6948e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 20/360\n",
      "20/20 [==============================] - 73s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 21/360\n",
      "20/20 [==============================] - 69s 4s/step - loss: 8.8291 - masked_acc: 5.7537e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 22/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 23/360\n",
      "20/20 [==============================] - 71s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 24/360\n",
      "20/20 [==============================] - 69s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 25/360\n",
      "20/20 [==============================] - 69s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 26/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 27/360\n",
      "20/20 [==============================] - 71s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 28/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 5.8038e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 29/360\n",
      "20/20 [==============================] - 63s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 30/360\n",
      "20/20 [==============================] - 67s 4s/step - loss: 8.8291 - masked_acc: 5.8038e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 31/360\n",
      "20/20 [==============================] - 72s 4s/step - loss: 8.8320 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 32/360\n",
      "20/20 [==============================] - 67s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 33/360\n",
      "20/20 [==============================] - 67s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 34/360\n",
      "20/20 [==============================] - 67s 4s/step - loss: 8.8291 - masked_acc: 5.6243e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 35/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8291 - masked_acc: 5.6433e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 36/360\n",
      "20/20 [==============================] - 67s 4s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 37/360\n",
      "20/20 [==============================] - 70s 4s/step - loss: 8.8291 - masked_acc: 5.7339e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 38/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 39/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 40/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8291 - masked_acc: 5.8548e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 41/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 42/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 43/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 5.5218e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 44/360\n",
      "20/20 [==============================] - 67s 4s/step - loss: 8.8291 - masked_acc: 5.6915e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 45/360\n",
      "20/20 [==============================] - 67s 4s/step - loss: 8.8291 - masked_acc: 5.7176e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 46/360\n",
      "20/20 [==============================] - 67s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 47/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 5.7013e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 48/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 49/360\n",
      "20/20 [==============================] - 71s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 50/360\n",
      "20/20 [==============================] - 62s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 51/360\n",
      "20/20 [==============================] - 70s 4s/step - loss: 8.8291 - masked_acc: 5.6754e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 52/360\n",
      "20/20 [==============================] - 62s 3s/step - loss: 8.8291 - masked_acc: 5.6497e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 53/360\n",
      "20/20 [==============================] - 70s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 54/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 55/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 56/360\n",
      "20/20 [==============================] - 61s 3s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 57/360\n",
      "20/20 [==============================] - 72s 4s/step - loss: 8.8291 - masked_acc: 5.6561e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 58/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 5.7471e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 59/360\n",
      "20/20 [==============================] - 61s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 60/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 5.7045e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 61/360\n",
      "20/20 [==============================] - 61s 3s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 62/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0017 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 63/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 64/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 65/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 66/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 67/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 68/360\n",
      "20/20 [==============================] - 61s 3s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 69/360\n",
      "20/20 [==============================] - 69s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 70/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8291 - masked_acc: 5.7438e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 71/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8291 - masked_acc: 5.7143e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 72/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 73/360\n",
      "20/20 [==============================] - 61s 3s/step - loss: 8.8291 - masked_acc: 5.6721e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 74/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8320 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 75/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 76/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 5.7604e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 77/360\n",
      "20/20 [==============================] - 61s 3s/step - loss: 8.8291 - masked_acc: 5.5127e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 78/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8291 - masked_acc: 0.0017 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 79/360\n",
      "20/20 [==============================] - 69s 4s/step - loss: 8.8291 - masked_acc: 5.8275e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 80/360\n",
      "20/20 [==============================] - 59s 3s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 81/360\n",
      "20/20 [==============================] - 69s 4s/step - loss: 8.8291 - masked_acc: 5.5310e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 82/360\n",
      "20/20 [==============================] - 60s 3s/step - loss: 8.8291 - masked_acc: 5.7471e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 83/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 84/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 85/360\n",
      "20/20 [==============================] - 60s 3s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 86/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 87/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 88/360\n",
      "20/20 [==============================] - 60s 3s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 89/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 90/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 5.7837e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 91/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 92/360\n",
      "20/20 [==============================] - 70s 4s/step - loss: 8.8291 - masked_acc: 0.0017 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 93/360\n",
      "20/20 [==============================] - 61s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 94/360\n",
      "20/20 [==============================] - 72s 4s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 95/360\n",
      "20/20 [==============================] - 70s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 96/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 97/360\n",
      "20/20 [==============================] - 71s 4s/step - loss: 8.8291 - masked_acc: 5.7803e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 98/360\n",
      "20/20 [==============================] - 67s 4s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 99/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 100/360\n",
      "20/20 [==============================] - 72s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 101/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 102/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8331 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 103/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 104/360\n",
      "20/20 [==============================] - 67s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 105/360\n",
      "20/20 [==============================] - 61s 3s/step - loss: 8.8325 - masked_acc: 0.0017 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 106/360\n",
      "20/20 [==============================] - 71s 4s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 107/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 5.8720e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 108/360\n",
      "20/20 [==============================] - 61s 3s/step - loss: 8.8291 - masked_acc: 5.7670e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 109/360\n",
      "20/20 [==============================] - 70s 4s/step - loss: 8.8291 - masked_acc: 5.6306e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 110/360\n",
      "20/20 [==============================] - 63s 3s/step - loss: 8.8291 - masked_acc: 0.0017 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 111/360\n",
      "20/20 [==============================] - 109s 6s/step - loss: 8.8291 - masked_acc: 0.0023 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 112/360\n",
      "20/20 [==============================] - 45s 2s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 113/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 114/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 115/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 0.0017 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 116/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 117/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 118/360\n",
      "20/20 [==============================] - 67s 4s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 119/360\n",
      "20/20 [==============================] - 62s 3s/step - loss: 8.8291 - masked_acc: 5.7307e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 120/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 121/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8319 - masked_acc: 0.0017 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 122/360\n",
      "20/20 [==============================] - ETA: 0s - loss: 8.8291 - masked_acc: 5.9067e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n",
      "\u001b[1;32m      7\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;66;43;03m# decay_callback,\u001b[39;49;00m\n",
      "\u001b[1;32m      8\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcsv_logger\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      9\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcreate_model_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapgen\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcheckpoints\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmasked_acc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     10\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtensorboard_callback\u001b[49m\n",
      "\u001b[1;32m     11\u001b[0m \u001b[43m                                \u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;32m     12\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:1694\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n",
      "\u001b[1;32m   1679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m   1680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n",
      "\u001b[1;32m   1681\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n",
      "\u001b[1;32m   1682\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   1692\u001b[0m         steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution,\n",
      "\u001b[1;32m   1693\u001b[0m     )\n",
      "\u001b[0;32m-> 1694\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   1695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1696\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1697\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1699\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1702\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1703\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1705\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1706\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1707\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n",
      "\u001b[1;32m   1708\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n",
      "\u001b[1;32m   1709\u001b[0m }\n",
      "\u001b[1;32m   1710\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:2040\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   2036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n",
      "\u001b[1;32m   2037\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;32m   2038\u001b[0m ):\n",
      "\u001b[1;32m   2039\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n",
      "\u001b[0;32m-> 2040\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   2041\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n",
      "\u001b[1;32m   2042\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n",
      "\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32m    916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[1;32m    917\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n",
      "\u001b[1;32m    918\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n",
      "\u001b[0;32m--> 919\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n",
      "\u001b[1;32m    921\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    922\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "\u001b[1;32m    132\u001b[0m   (concrete_function,\n",
      "\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n",
      "\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n",
      "\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n",
      "\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n",
      "\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n",
      "\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n",
      "\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n",
      "\u001b[1;32m   1748\u001b[0m     args,\n",
      "\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n",
      "\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n",
      "\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n",
      "\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n",
      "\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n",
      "\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n",
      "\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n",
      "\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n",
      "\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data.repeat(),\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=val_data,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps,\n",
    "                    callbacks=[\n",
    "                        # decay_callback,\n",
    "                        csv_logger,\n",
    "                        create_model_checkpoint(model_name = 'capgen', save_dir = 'checkpoints', monitor = 'masked_acc'),\n",
    "                        tensorboard_callback\n",
    "                                ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcyou.plot import plot_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m plot_history(\u001b[43mhistory\u001b[49m,plot \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmasked_acc\u001b[39m\u001b[38;5;124m'\u001b[39m], split \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m], )\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_history(history,plot = ['loss','masked_acc'], split = ['train','val'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs/gradient_tape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(f'saved_model/best-{datetime.now()}-{EPOCHS}.h5')\n",
    "# model.save_weights(f'model_weights/best_so_far_final/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la -h 'saved_model/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_data.take(1))\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppred = tf.argmax(pred, axis = -1)\n",
    "print(ppred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ppred:\n",
    "    print(tf.strings.join(id_to_word(i), ' ').numpy())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_new",
   "language": "python",
   "name": "tf_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
