{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system('git clone https://github.com/tikendraw/caption-generator.git -q')\n",
    "# os.chdir('caption-generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 16:33:55.923830: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-21 16:33:57.249475: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-05-21 16:33:59.811719: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-21 16:34:00.019898: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-21 16:34:00.020600: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-21 16:34:00.024077: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-21 16:34:00.024735: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-21 16:34:00.025257: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-21 16:34:01.323455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-21 16:34:01.323717: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-21 16:34:01.323890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-21 16:34:01.324016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2141 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random, math\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import shutil\n",
    "from zipfile import ZipFile\n",
    "import datetime\n",
    "import sys\n",
    "from functools import cache\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import regex as re\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocessing\n",
    "from tensorflow.keras.layers import (\n",
    "    TextVectorization, Embedding, LSTM, GRU, Bidirectional, TimeDistributed, Dense, Attention, MultiHeadAttention, Flatten, Dropout,\n",
    "    Concatenate, Activation, GlobalAveragePooling2D\n",
    "    )\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Input, Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import array_to_img, img_to_array\n",
    "import string\n",
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, TensorBoard\n",
    "from model import LearningRateDecayCallback, get_model, masked_acc, masked_loss\n",
    "from preprocessing import preprocess_text, embedding_matrix_creater, mapper, clean_words\n",
    "from utils import create_model_checkpoint\n",
    "\n",
    "from config import config\n",
    "\n",
    "from get_data import download_dataset\n",
    "from funcyou.dataset import download_kaggle_dataset\n",
    "import polars as pl\n",
    "from preprocess_data import clean_the_df\n",
    "from funcyou.utils import printt, dir_walk\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import regex as re\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_path = './config.yaml'\n",
    "\n",
    "# Read the config file \n",
    "with open(config_file_path, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "\n",
    "RAW_CAPTION_FILE                        = Path(config['raw_caption_file'])\n",
    "CAPTION_FILE                            = Path(config['caption_file'])\n",
    "IMAGE_DIR                               = Path(config['image_dir'])\n",
    "IMG_SIZE                                = config['img_size']\n",
    "CHANNELS                                = config['channels']\n",
    "IMG_SHAPE                               = config['img_shape']\n",
    "MAX_LEN                                 = config['max_len']\n",
    "BATCH_SIZE                              = config['batch_size']\n",
    "EPOCHS                                  = config['epochs']\n",
    "LEARNING_RATE                           = config['learning_rate']\n",
    "UNITS                                   = config['units']\n",
    "TEST_SIZE                               = config['test_size']\n",
    "VALIDATION_SIZE                         = config['val_size']\n",
    "EMBEDDING_DIMENSION                     = config['embedding_dimension']\n",
    "GLOVE_PATH                              = config['glove_path']\n",
    "D_MODEL                                 = config['d_model']\n",
    "NUM_HEADS                               = config['num_heads']    \n",
    "NUM_LAYERS                               = config['num_layers']    \n",
    "PATCH_SIZE                              = config['patch_size']    \n",
    "TRANSFORMER_LAYERS                      = config['transformer_layers']        \n",
    "\n",
    "NUM_PATCHES = (IMG_SIZE // PATCH_SIZE) ** 2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      RAW_CAPTION_FILE=PosixPath('input/flickr30k/results.csv')\n",
      "CAPTION_FILE=PosixPath('input/flickr30k/results_cleaned.csv')\n",
      "IMAGE_DIR=PosixPath('input/flickr30k/images')\n",
      "IMG_SIZE=256\n",
      "CHANNELS=3\n",
      "IMG_SHAPE=[256, 256, 3]\n",
      "MAX_LEN=50\n",
      "BATCH_SIZE=8\n",
      "EPOCHS=10\n",
      "LEARNING_RATE=0.01\n",
      "UNITS=16\n",
      "TEST_SIZE=0.05\n",
      "VALIDATION_SIZE=0.05\n",
      "EMBEDDING_DIMENSION=50\n",
      "GLOVE_PATH='embedding/glove.6B.50d.zip'\n",
      "D_MODEL=128\n",
      "NUM_HEADS=4\n",
      "NUM_LAYERS=4\n",
      "PATCH_SIZE=42\n",
      "TRANSFORMER_LAYERS=8\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "{      RAW_CAPTION_FILE=}\n",
    "{CAPTION_FILE=}\n",
    "{IMAGE_DIR=}\n",
    "{IMG_SIZE=}\n",
    "{CHANNELS=}\n",
    "{IMG_SHAPE=}\n",
    "{MAX_LEN=}\n",
    "{BATCH_SIZE=}\n",
    "{EPOCHS=}\n",
    "{LEARNING_RATE=}\n",
    "{UNITS=}\n",
    "{TEST_SIZE=}\n",
    "{VALIDATION_SIZE=}\n",
    "{EMBEDDING_DIMENSION=}\n",
    "{GLOVE_PATH=}\n",
    "{D_MODEL=}\n",
    "{NUM_HEADS=}\n",
    "{NUM_LAYERS=}\n",
    "{PATCH_SIZE=}\n",
    "{TRANSFORMER_LAYERS=}\n",
    "      ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 8\n",
    "IMG_SHAPE = (128,128,3)\n",
    "D_MODEL = 32\n",
    "MAX_LEN = 30\n",
    "PATCH_SIZE = 32\n",
    "NUM_PATCHES = (IMG_SIZE // PATCH_SIZE) ** 2\n",
    "NUM_PATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN = 'startseq'\n",
    "END_TOKEN = 'endseq'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curating Dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Null/Bad Entries removed\n",
    "2. Columns names stripped and lowered\n",
    "3. Low frequency word (<5) has been removed \n",
    "4. Added start and end tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are keeping words in comments which atleast has occured  5 times( there are unnecessary word which we don't want) \n",
    "there are ~12000 words that doesn't even gets repeated 5 times in 150000 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_the_df(RAW_CAPTION_FILE, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>image_name</th><th>comment_number</th><th>comment</th><th>no_rare_words</th><th>sent_len</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>bool</td><td>i64</td></tr></thead><tbody><tr><td>&quot;1000092795.jpg…</td><td>0</td><td>&quot;startseq  Two …</td><td>true</td><td>18</td></tr><tr><td>&quot;1000092795.jpg…</td><td>1</td><td>&quot;startseq  Two …</td><td>true</td><td>11</td></tr><tr><td>&quot;1000092795.jpg…</td><td>2</td><td>&quot;startseq  Two …</td><td>true</td><td>12</td></tr><tr><td>&quot;1000092795.jpg…</td><td>3</td><td>&quot;startseq  A ma…</td><td>true</td><td>12</td></tr><tr><td>&quot;1000092795.jpg…</td><td>4</td><td>&quot;startseq  Two …</td><td>true</td><td>7</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌────────────────┬────────────────┬───────────────────────────────────┬───────────────┬──────────┐\n",
       "│ image_name     ┆ comment_number ┆ comment                           ┆ no_rare_words ┆ sent_len │\n",
       "│ ---            ┆ ---            ┆ ---                               ┆ ---           ┆ ---      │\n",
       "│ str            ┆ i64            ┆ str                               ┆ bool          ┆ i64      │\n",
       "╞════════════════╪════════════════╪═══════════════════════════════════╪═══════════════╪══════════╡\n",
       "│ 1000092795.jpg ┆ 0              ┆ startseq  Two young guys with sh… ┆ true          ┆ 18       │\n",
       "│ 1000092795.jpg ┆ 1              ┆ startseq  Two young White males … ┆ true          ┆ 11       │\n",
       "│ 1000092795.jpg ┆ 2              ┆ startseq  Two men in green shirt… ┆ true          ┆ 12       │\n",
       "│ 1000092795.jpg ┆ 3              ┆ startseq  A man in a blue shirt … ┆ true          ┆ 12       │\n",
       "│ 1000092795.jpg ┆ 4              ┆ startseq  Two friends enjoy time… ┆ true          ┆ 7        │\n",
       "└────────────────┴────────────────┴───────────────────────────────────┴───────────────┴──────────┘"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_csv('cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete before this code \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned.csv')\n",
    "\n",
    "try:\n",
    "    df.drop('Unnamed: 0',axis=1, inplace=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158914, 5)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 158914 entries, 0 to 158913\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   image_name      158914 non-null  object\n",
      " 1   comment_number  158914 non-null  int64 \n",
      " 2   comment         158914 non-null  object\n",
      " 3   no_rare_words   158914 non-null  bool  \n",
      " 4   sent_len        158914 non-null  int64 \n",
      "dtypes: bool(1), int64(2), object(2)\n",
      "memory usage: 5.0+ MB\n",
      "None\n",
      "['image_name', 'comment_number', 'comment', 'no_rare_words', 'sent_len']\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.to_pandas().info())\n",
    "print(df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **For the Sake of COmputation power and time we will train with one caption per image rather than 5 caption per image**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding median sentence length for all class of comment numbers, to ensure that our MAX_LEN covers all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>image_name</th><th>comment_number</th><th>comment</th><th>no_rare_words</th><th>sent_len</th><th>image_path</th><th>img_exists</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>bool</td><td>i64</td><td>str</td><td>bool</td></tr></thead><tbody><tr><td>&quot;1000092795.jpg…</td><td>0</td><td>&quot;startseq  Two …</td><td>true</td><td>18</td><td>&quot;input/flickr30…</td><td>true</td></tr><tr><td>&quot;1000092795.jpg…</td><td>1</td><td>&quot;startseq  Two …</td><td>true</td><td>11</td><td>&quot;input/flickr30…</td><td>true</td></tr><tr><td>&quot;1000092795.jpg…</td><td>2</td><td>&quot;startseq  Two …</td><td>true</td><td>12</td><td>&quot;input/flickr30…</td><td>true</td></tr><tr><td>&quot;1000092795.jpg…</td><td>3</td><td>&quot;startseq  A ma…</td><td>true</td><td>12</td><td>&quot;input/flickr30…</td><td>true</td></tr><tr><td>&quot;1000092795.jpg…</td><td>4</td><td>&quot;startseq  Two …</td><td>true</td><td>7</td><td>&quot;input/flickr30…</td><td>true</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌──────────────┬──────────────┬──────────────┬──────────────┬──────────┬──────────────┬────────────┐\n",
       "│ image_name   ┆ comment_numb ┆ comment      ┆ no_rare_word ┆ sent_len ┆ image_path   ┆ img_exists │\n",
       "│ ---          ┆ er           ┆ ---          ┆ s            ┆ ---      ┆ ---          ┆ ---        │\n",
       "│ str          ┆ ---          ┆ str          ┆ ---          ┆ i64      ┆ str          ┆ bool       │\n",
       "│              ┆ i64          ┆              ┆ bool         ┆          ┆              ┆            │\n",
       "╞══════════════╪══════════════╪══════════════╪══════════════╪══════════╪══════════════╪════════════╡\n",
       "│ 1000092795.j ┆ 0            ┆ startseq     ┆ true         ┆ 18       ┆ input/flickr ┆ true       │\n",
       "│ pg           ┆              ┆ Two young    ┆              ┆          ┆ 30k/images/1 ┆            │\n",
       "│              ┆              ┆ guys with    ┆              ┆          ┆ 00009279…    ┆            │\n",
       "│              ┆              ┆ sh…          ┆              ┆          ┆              ┆            │\n",
       "│ 1000092795.j ┆ 1            ┆ startseq     ┆ true         ┆ 11       ┆ input/flickr ┆ true       │\n",
       "│ pg           ┆              ┆ Two young    ┆              ┆          ┆ 30k/images/1 ┆            │\n",
       "│              ┆              ┆ White males  ┆              ┆          ┆ 00009279…    ┆            │\n",
       "│              ┆              ┆ …            ┆              ┆          ┆              ┆            │\n",
       "│ 1000092795.j ┆ 2            ┆ startseq     ┆ true         ┆ 12       ┆ input/flickr ┆ true       │\n",
       "│ pg           ┆              ┆ Two men in   ┆              ┆          ┆ 30k/images/1 ┆            │\n",
       "│              ┆              ┆ green shirt… ┆              ┆          ┆ 00009279…    ┆            │\n",
       "│ 1000092795.j ┆ 3            ┆ startseq  A  ┆ true         ┆ 12       ┆ input/flickr ┆ true       │\n",
       "│ pg           ┆              ┆ man in a     ┆              ┆          ┆ 30k/images/1 ┆            │\n",
       "│              ┆              ┆ blue shirt … ┆              ┆          ┆ 00009279…    ┆            │\n",
       "│ 1000092795.j ┆ 4            ┆ startseq     ┆ true         ┆ 7        ┆ input/flickr ┆ true       │\n",
       "│ pg           ┆              ┆ Two friends  ┆              ┆          ┆ 30k/images/1 ┆            │\n",
       "│              ┆              ┆ enjoy time…  ┆              ┆          ┆ 00009279…    ┆            │\n",
       "└──────────────┴──────────────┴──────────────┴──────────────┴──────────┴──────────────┴────────────┘"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.with_columns([\n",
    "    pl.col(\"image_name\").apply(lambda x: str(IMAGE_DIR / x) ).alias('image_path') \n",
    "])\n",
    "\n",
    "df = df.with_columns([\n",
    "    pl.col(\"image_path\").apply(lambda x: os.path.isfile(x)).alias('img_exists') \n",
    "])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>comment_number</th><th>mean</th><th>median</th><th>min</th><th>max</th><th>count</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>19.871315</td><td>19.0</td><td>6</td><td>79</td><td>31783</td></tr><tr><td>1</td><td>15.859327</td><td>15.0</td><td>6</td><td>41</td><td>31783</td></tr><tr><td>2</td><td>13.602869</td><td>13.0</td><td>4</td><td>34</td><td>31783</td></tr><tr><td>3</td><td>11.771639</td><td>11.0</td><td>4</td><td>36</td><td>31783</td></tr><tr><td>4</td><td>9.871437</td><td>10.0</td><td>3</td><td>38</td><td>31782</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 6)\n",
       "┌────────────────┬───────────┬────────┬─────┬─────┬───────┐\n",
       "│ comment_number ┆ mean      ┆ median ┆ min ┆ max ┆ count │\n",
       "│ ---            ┆ ---       ┆ ---    ┆ --- ┆ --- ┆ ---   │\n",
       "│ i64            ┆ f64       ┆ f64    ┆ i64 ┆ i64 ┆ u32   │\n",
       "╞════════════════╪═══════════╪════════╪═════╪═════╪═══════╡\n",
       "│ 0              ┆ 19.871315 ┆ 19.0   ┆ 6   ┆ 79  ┆ 31783 │\n",
       "│ 1              ┆ 15.859327 ┆ 15.0   ┆ 6   ┆ 41  ┆ 31783 │\n",
       "│ 2              ┆ 13.602869 ┆ 13.0   ┆ 4   ┆ 34  ┆ 31783 │\n",
       "│ 3              ┆ 11.771639 ┆ 11.0   ┆ 4   ┆ 36  ┆ 31783 │\n",
       "│ 4              ┆ 9.871437  ┆ 10.0   ┆ 3   ┆ 38  ┆ 31782 │\n",
       "└────────────────┴───────────┴────────┴─────┴─────┴───────┘"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by a categorical column\n",
    "grouped = df.groupby('comment_number')\n",
    "\n",
    "# Apply aggregation functions on numerical columns\n",
    "aggregated = grouped.agg(\n",
    "    pl.col('sent_len').mean().alias('mean'), \n",
    "    pl.col('sent_len').median().alias('median'), \n",
    "    pl.col('sent_len').min().alias('min'), \n",
    "    pl.col('sent_len').max().alias('max'), \n",
    "    pl.col('sent_len').count().alias('count')\n",
    ")\n",
    "aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31783, 7)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i randomly chose 2nd comment of all picture you can chose anything bw 0 to 4\n",
    "df = df.filter(\n",
    "    (pl.col(\"comment_number\") == 1) & (pl.col(\"img_exists\") == True) & (pl.col(\"sent_len\") < 51)\n",
    ")\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we are just using 1/5 dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "\n",
    "    text = tf.strings.lower(text)\n",
    "\n",
    "    text = tf.strings.regex_replace(text, r'\\d', '')\n",
    "\n",
    "    # Remove any punctuations\n",
    "    text = tf.strings.regex_replace(text, '[%s]' % re.escape(\n",
    "        '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'), '')\n",
    "\n",
    "    # Remove single characters\n",
    "    text = tf.strings.regex_replace(text, r'\\b\\w\\b', '')\n",
    "    # Keep space, a to z, and select punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
    "    # Add spaces around punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[.?!,¿|]', r' \\0 ')\n",
    "    # Strip whitespace.\n",
    "    text = tf.strings.strip(text)\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#tokenizer\n",
    "tokenizer = TextVectorization(standardize=preprocess_text)\n",
    "tokenizer.adapt(df['comment'].to_list())\n",
    "\n",
    "\n",
    "word_to_id = tf.keras.layers.StringLookup(vocabulary=tokenizer.get_vocabulary(), mask_token='', oov_token='[UNK]')\n",
    "id_to_word = tf.keras.layers.StringLookup(vocabulary=tokenizer.get_vocabulary(), mask_token='', oov_token='[UNK]', invert=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# making Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mapper(x, y, tokenizer):\n",
    "    x = load_images_now(x)\n",
    "    y = tokenizer(y)\n",
    "\n",
    "    y_in = y[:-1]\n",
    "    y_in =  tf.pad(y_in, [[0, MAX_LEN - tf.shape(y_in)[0]]] , constant_values=0)\n",
    "\n",
    "    y_out = y[1:]\n",
    "    y_out =  tf.pad(y_out, [[0, MAX_LEN - tf.shape(y_out)[0]]], constant_values=0)\n",
    "\n",
    "    return (x, y_in), y_out\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def load_images_now(x):\n",
    "    image_data = tf.io.read_file(x)\n",
    "    image_features = tf.image.decode_jpeg(image_data, channels=CHANNELS)\n",
    "    image_features = tf.image.resize_with_pad(\n",
    "        image_features, target_height=IMG_SIZE, target_width=IMG_SIZE)\n",
    "    return image_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_filepath = random.choices(df['image_path'].to_list(), k=1)[0]\n",
    "p_image = load_images_now(str(random_image_filepath))\n",
    "array_to_img(p_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 3586\n",
      "Number of validation samples: 199\n",
      "Number of test samples: 189\n",
      "Vocabulary size: 7102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 16:36:02.231331: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'args_0' with dtype string\n",
      "\t [[{{node args_0}}]]\n",
      "2023-05-21 16:36:02.290348: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'args_0' with dtype string\n",
      "\t [[{{node args_0}}]]\n",
      "2023-05-21 16:36:02.349749: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'args_0' with dtype string\n",
      "\t [[{{node args_0}}]]\n"
     ]
    }
   ],
   "source": [
    "# Creating dataset\n",
    "TEST_SIZE = config['test_size']\n",
    "VAL_SIZE =  config['val_size']\n",
    "\n",
    "train, val = train_test_split(\n",
    "    df[['image_path', 'comment']],  test_size=VAL_SIZE, random_state=11)\n",
    "train, test = train_test_split(\n",
    "    train[['image_path', 'comment']],  test_size=TEST_SIZE, random_state=11)\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((train['image_path'].to_list(), train['comment'].to_list()))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((test['image_path'].to_list(), test['comment'].to_list()))\n",
    "val_data = tf.data.Dataset.from_tensor_slices((val['image_path'].to_list(), val['comment'].to_list()))\n",
    "\n",
    "\n",
    "train_data = train_data.map(lambda x,y:mapper(x, y, tokenizer)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_data =   test_data.map(lambda x,y:mapper(x, y, tokenizer)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_data =     val_data.map(lambda x,y:mapper(x, y, tokenizer)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# resnet_output_flattened_shape = 8*8*2048\n",
    "\n",
    "print(\"Number of training samples: %d\" %\n",
    "      tf.data.experimental.cardinality(train_data))\n",
    "print(\"Number of validation samples: %d\" %\n",
    "      tf.data.experimental.cardinality(val_data))\n",
    "print(\"Number of test samples: %d\" %\n",
    "      tf.data.experimental.cardinality(test_data))\n",
    "\n",
    "VOCAB_SIZE = tokenizer.vocabulary_size()\n",
    "print(\"Vocabulary size: %d\" % VOCAB_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28683, 2), 28688)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, len(train_data)*BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x     :  (8, 128, 128, 3)\n",
      "y_in.shape(one batch)  :  (8, 30)\n",
      "y_in  :  tf.Tensor(\n",
      "[   2 1710   31    8  580    6    4  192   11   56    9  326  251    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0], shape=(30,), dtype=int64)\n",
      "y_out.shape(one batch)  :  (8, 30)\n",
      "y_out :  tf.Tensor(\n",
      "[1710   31    8  580    6    4  192   11   56    9  326  251    3    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0], shape=(30,), dtype=int64)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 16:36:02.459565: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    }
   ],
   "source": [
    "for (img_in, txt_in), txt_out in train_data.take(1):\n",
    "    # print(f'{i.numpy().decode():<40} {j.numpy()}')\n",
    "    print('x     : ', img_in.shape)\n",
    "    print('y_in.shape(one batch)  : ', txt_in.shape)\n",
    "    \n",
    "    print('y_in  : ', txt_in[0])\n",
    "    \n",
    "    print('y_out.shape(one batch)  : ', txt_out.shape)\n",
    "    print('y_out : ', txt_out[0])\n",
    "    print('\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import CaptionGenerator, Encoder, Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "enc = Encoder( NUM_LAYERS, D_MODEL, NUM_HEADS, DFF, PATCH_SIZE, NUM_PATCHES, dropout_rate=0.1)\n",
    "dec = Decoder( NUM_LAYERS, D_MODEL, NUM_HEADS, DFF, VOCAB_SIZE, dropout_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFF = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CaptionGenerator(NUM_LAYERS, D_MODEL, NUM_HEADS, DFF, VOCAB_SIZE, PATCH_SIZE, NUM_PATCHES, dropout_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorShape([16])\n",
      "attn_output:  TensorShape([8, 16, 32])\n",
      "concat:  TensorShape([8, 16, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 16:36:03.522897: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.1.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-05-21 16:36:03.523940: W ./tensorflow/compiler/xla/stream_executor/stream.h:1583] attempting to perform DNN operation using StreamExecutor without DNN support\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Exception encountered when calling layer 'layer_normalization_32' (type LayerNormalization).\n\n{{function_node __wrapped__FusedBatchNormV3_device_/job:localhost/replica:0/task:0/device:GPU:0}} cuDNN launch failure : input shape ([1,128,32,1]) [Op:FusedBatchNormV3]\n\nCall arguments received by layer 'layer_normalization_32' (type LayerNormalization):\n  • inputs=tf.Tensor(shape=(8, 16, 32), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[39m=\u001b[39m model((img_in, txt_in))\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_new/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/cproject/caption-generator/transformer.py:369\u001b[0m, in \u001b[0;36mCaptionGenerator.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs):  \u001b[39m# sourcery skip: inline-immediately-returned-variable, use-contextlib-suppress\u001b[39;00m\n\u001b[1;32m    367\u001b[0m     img, txt  \u001b[39m=\u001b[39m inputs\n\u001b[0;32m--> 369\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(img)  \u001b[39m# (batch_size, context_len, d_model)\u001b[39;00m\n\u001b[1;32m    371\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(x\u001b[39m=\u001b[39mtxt, context\u001b[39m=\u001b[39mimg)  \u001b[39m# (batch_size, target_len, d_model)\u001b[39;00m\n\u001b[1;32m    373\u001b[0m     \u001b[39m# Final linear layer output.\u001b[39;00m\n",
      "File \u001b[0;32m~/cproject/caption-generator/transformer.py:264\u001b[0m, in \u001b[0;36mEncoder.call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    261\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x)\n\u001b[1;32m    263\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers):\n\u001b[0;32m--> 264\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menc_layers[i](x)\n\u001b[1;32m    266\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/cproject/caption-generator/transformer.py:224\u001b[0m, in \u001b[0;36mEncoderLayer.call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 224\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attention(x)\n\u001b[1;32m    225\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mffn(x)\n\u001b[1;32m    226\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/cproject/caption-generator/transformer.py:175\u001b[0m, in \u001b[0;36mGlobalSelfAttention.call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    172\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd([x, attn_output])\n\u001b[1;32m    173\u001b[0m tf\u001b[39m.\u001b[39mprint(\u001b[39m'\u001b[39m\u001b[39mconcat: \u001b[39m\u001b[39m'\u001b[39m,x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m--> 175\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayernorm(x)\n\u001b[1;32m    176\u001b[0m tf\u001b[39m.\u001b[39mprint(\u001b[39m'\u001b[39m\u001b[39mlayernorm: \u001b[39m\u001b[39m'\u001b[39m,x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    178\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[0;31mInternalError\u001b[0m: Exception encountered when calling layer 'layer_normalization_32' (type LayerNormalization).\n\n{{function_node __wrapped__FusedBatchNormV3_device_/job:localhost/replica:0/task:0/device:GPU:0}} cuDNN launch failure : input shape ([1,128,32,1]) [Op:FusedBatchNormV3]\n\nCall arguments received by layer 'layer_normalization_32' (type LayerNormalization):\n  • inputs=tf.Tensor(shape=(8, 16, 32), dtype=float32)"
     ]
    }
   ],
   "source": [
    "output = model((img_in, txt_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 36, 128])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = tf.random.uniform((8,36,128))\n",
    "ss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 16:13:50.042305: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.1.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-05-21 16:13:50.045576: W ./tensorflow/compiler/xla/stream_executor/stream.h:1583] attempting to perform DNN operation using StreamExecutor without DNN support\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Exception encountered when calling layer 'layer_normalization_32' (type LayerNormalization).\n\n{{function_node __wrapped__FusedBatchNormV3_device_/job:localhost/replica:0/task:0/device:GPU:0}} cuDNN launch failure : input shape ([1,288,128,1]) [Op:FusedBatchNormV3]\n\nCall arguments received by layer 'layer_normalization_32' (type LayerNormalization):\n  • inputs=tf.Tensor(shape=(8, 36, 128), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ln \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mLayerNormalization()\n\u001b[0;32m----> 2\u001b[0m sss \u001b[39m=\u001b[39m ln(ss)\n\u001b[1;32m      3\u001b[0m sss\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_new/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_new/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7261\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7262\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mInternalError\u001b[0m: Exception encountered when calling layer 'layer_normalization_32' (type LayerNormalization).\n\n{{function_node __wrapped__FusedBatchNormV3_device_/job:localhost/replica:0/task:0/device:GPU:0}} cuDNN launch failure : input shape ([1,288,128,1]) [Op:FusedBatchNormV3]\n\nCall arguments received by layer 'layer_normalization_32' (type LayerNormalization):\n  • inputs=tf.Tensor(shape=(8, 36, 128), dtype=float32)"
     ]
    }
   ],
   "source": [
    "ln = tf.keras.layers.LayerNormalization()\n",
    "sss = ln(ss)\n",
    "sss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def masked_loss(y_true, y_pred):\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        reduction='none')\n",
    "    loss = loss_fn(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(y_true != 0, loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "\n",
    "def masked_acc(y_true, y_pred):\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
    "\n",
    "    matchh = tf.cast(y_true == y_pred, tf.float32)\n",
    "    mask = tf.cast(y_true != 0, tf.float32)\n",
    "\n",
    "    return tf.reduce_sum(matchh)/tf.reduce_sum(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    }
   ],
   "source": [
    "print(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "              loss=masked_loss,\n",
    "              metrics=[masked_acc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x79b6ee33bb20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.load_weights(f'model_weights/best_so_far/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('log', exist_ok=True)\n",
    "csv_logger = CSVLogger('./log/training.log',append=True )\n",
    "tb_callback = tf.keras.callbacks.TensorBoard('./logs', update_freq=1)\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0\n",
      "20 1\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 360\n",
    "print(len(train_data) // EPOCHS, len(val_data) // EPOCHS)\n",
    "\n",
    "# steps_per_epoch = int(1*(len(train_data) / EPOCHS))\n",
    "# validation_steps =  int(1*(len(val_data) / EPOCHS))\n",
    "# print(steps_per_epoch, validation_steps)\n",
    "\n",
    "steps_per_epoch = 20\n",
    "validation_steps = 1\n",
    "print(steps_per_epoch, validation_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3586, 199, 189)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'expected_loss': 8.829079952564836, 'expected_acc': 0.00014641288433382137}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "{\"expected_loss\": np.log(VOCAB_SIZE),\n",
    " \"expected_acc\": 1/VOCAB_SIZE}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/360\n",
      "20/20 [==============================] - 120s 5s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 2/360\n",
      "20/20 [==============================] - 63s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 3/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 4/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 5/360\n",
      "20/20 [==============================] - 71s 4s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 6/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 7/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8315 - masked_acc: 5.6306e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 8/360\n",
      "20/20 [==============================] - 108s 6s/step - loss: 8.8291 - masked_acc: 0.0023 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 9/360\n",
      "20/20 [==============================] - 51s 3s/step - loss: 8.8291 - masked_acc: 5.6948e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 10/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8320 - masked_acc: 5.9312e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 11/360\n",
      "20/20 [==============================] - 69s 4s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 12/360\n",
      "20/20 [==============================] - 69s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 13/360\n",
      "20/20 [==============================] - 73s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 14/360\n",
      "20/20 [==============================] - 70s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 15/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 16/360\n",
      "20/20 [==============================] - 71s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 17/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 5.6948e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 18/360\n",
      "20/20 [==============================] - 72s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 19/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8291 - masked_acc: 5.6948e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 20/360\n",
      "20/20 [==============================] - 73s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 21/360\n",
      "20/20 [==============================] - 69s 4s/step - loss: 8.8291 - masked_acc: 5.7537e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 22/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 23/360\n",
      "20/20 [==============================] - 71s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 24/360\n",
      "20/20 [==============================] - 69s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 25/360\n",
      "20/20 [==============================] - 69s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 26/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 27/360\n",
      "20/20 [==============================] - 71s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 28/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 5.8038e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 29/360\n",
      "20/20 [==============================] - 63s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 30/360\n",
      "20/20 [==============================] - 67s 4s/step - loss: 8.8291 - masked_acc: 5.8038e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 31/360\n",
      "20/20 [==============================] - 72s 4s/step - loss: 8.8320 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 32/360\n",
      "20/20 [==============================] - 67s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 33/360\n",
      "20/20 [==============================] - 67s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 34/360\n",
      "20/20 [==============================] - 67s 4s/step - loss: 8.8291 - masked_acc: 5.6243e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 35/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8291 - masked_acc: 5.6433e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 36/360\n",
      "20/20 [==============================] - 67s 4s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 37/360\n",
      "20/20 [==============================] - 70s 4s/step - loss: 8.8291 - masked_acc: 5.7339e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 38/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 39/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 40/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8291 - masked_acc: 5.8548e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 41/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 42/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 43/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 5.5218e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 44/360\n",
      "20/20 [==============================] - 67s 4s/step - loss: 8.8291 - masked_acc: 5.6915e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 45/360\n",
      "20/20 [==============================] - 67s 4s/step - loss: 8.8291 - masked_acc: 5.7176e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 46/360\n",
      "20/20 [==============================] - 67s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 47/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 5.7013e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 48/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 49/360\n",
      "20/20 [==============================] - 71s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 50/360\n",
      "20/20 [==============================] - 62s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 51/360\n",
      "20/20 [==============================] - 70s 4s/step - loss: 8.8291 - masked_acc: 5.6754e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 52/360\n",
      "20/20 [==============================] - 62s 3s/step - loss: 8.8291 - masked_acc: 5.6497e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 53/360\n",
      "20/20 [==============================] - 70s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 54/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 55/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 56/360\n",
      "20/20 [==============================] - 61s 3s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 57/360\n",
      "20/20 [==============================] - 72s 4s/step - loss: 8.8291 - masked_acc: 5.6561e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 58/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 5.7471e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 59/360\n",
      "20/20 [==============================] - 61s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 60/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 5.7045e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 61/360\n",
      "20/20 [==============================] - 61s 3s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 62/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0017 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 63/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 64/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 65/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 66/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 67/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 68/360\n",
      "20/20 [==============================] - 61s 3s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 69/360\n",
      "20/20 [==============================] - 69s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 70/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8291 - masked_acc: 5.7438e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 71/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8291 - masked_acc: 5.7143e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 72/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 73/360\n",
      "20/20 [==============================] - 61s 3s/step - loss: 8.8291 - masked_acc: 5.6721e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 74/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8320 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 75/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 76/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 5.7604e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 77/360\n",
      "20/20 [==============================] - 61s 3s/step - loss: 8.8291 - masked_acc: 5.5127e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 78/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8291 - masked_acc: 0.0017 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 79/360\n",
      "20/20 [==============================] - 69s 4s/step - loss: 8.8291 - masked_acc: 5.8275e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 80/360\n",
      "20/20 [==============================] - 59s 3s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 81/360\n",
      "20/20 [==============================] - 69s 4s/step - loss: 8.8291 - masked_acc: 5.5310e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 82/360\n",
      "20/20 [==============================] - 60s 3s/step - loss: 8.8291 - masked_acc: 5.7471e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 83/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 84/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 85/360\n",
      "20/20 [==============================] - 60s 3s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 86/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 87/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 88/360\n",
      "20/20 [==============================] - 60s 3s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 89/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 90/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 5.7837e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 91/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 92/360\n",
      "20/20 [==============================] - 70s 4s/step - loss: 8.8291 - masked_acc: 0.0017 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 93/360\n",
      "20/20 [==============================] - 61s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 94/360\n",
      "20/20 [==============================] - 72s 4s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 95/360\n",
      "20/20 [==============================] - 70s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 96/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 97/360\n",
      "20/20 [==============================] - 71s 4s/step - loss: 8.8291 - masked_acc: 5.7803e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 98/360\n",
      "20/20 [==============================] - 67s 4s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 99/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 100/360\n",
      "20/20 [==============================] - 72s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 101/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 102/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8331 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 103/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 104/360\n",
      "20/20 [==============================] - 67s 4s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 105/360\n",
      "20/20 [==============================] - 61s 3s/step - loss: 8.8325 - masked_acc: 0.0017 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 106/360\n",
      "20/20 [==============================] - 71s 4s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 107/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 5.8720e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 108/360\n",
      "20/20 [==============================] - 61s 3s/step - loss: 8.8291 - masked_acc: 5.7670e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 109/360\n",
      "20/20 [==============================] - 70s 4s/step - loss: 8.8291 - masked_acc: 5.6306e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 110/360\n",
      "20/20 [==============================] - 63s 3s/step - loss: 8.8291 - masked_acc: 0.0017 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 111/360\n",
      "20/20 [==============================] - 109s 6s/step - loss: 8.8291 - masked_acc: 0.0023 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 112/360\n",
      "20/20 [==============================] - 45s 2s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 113/360\n",
      "20/20 [==============================] - 64s 3s/step - loss: 8.8291 - masked_acc: 0.0011 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 114/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 0.0000e+00 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 115/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 0.0017 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 116/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 117/360\n",
      "20/20 [==============================] - 66s 3s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 118/360\n",
      "20/20 [==============================] - 67s 4s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 119/360\n",
      "20/20 [==============================] - 62s 3s/step - loss: 8.8291 - masked_acc: 5.7307e-04 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 120/360\n",
      "20/20 [==============================] - 68s 4s/step - loss: 8.8291 - masked_acc: 0.0012 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 121/360\n",
      "20/20 [==============================] - 65s 3s/step - loss: 8.8319 - masked_acc: 0.0017 - val_loss: 8.8291 - val_masked_acc: 0.0000e+00\n",
      "Epoch 122/360\n",
      "20/20 [==============================] - ETA: 0s - loss: 8.8291 - masked_acc: 5.9067e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n",
      "\u001b[1;32m      7\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;66;43;03m# decay_callback,\u001b[39;49;00m\n",
      "\u001b[1;32m      8\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcsv_logger\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      9\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcreate_model_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapgen\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcheckpoints\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmasked_acc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     10\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtensorboard_callback\u001b[49m\n",
      "\u001b[1;32m     11\u001b[0m \u001b[43m                                \u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;32m     12\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:1694\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n",
      "\u001b[1;32m   1679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m   1680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n",
      "\u001b[1;32m   1681\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n",
      "\u001b[1;32m   1682\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   1692\u001b[0m         steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution,\n",
      "\u001b[1;32m   1693\u001b[0m     )\n",
      "\u001b[0;32m-> 1694\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   1695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1696\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1697\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1699\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1702\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1703\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1705\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1706\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1707\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n",
      "\u001b[1;32m   1708\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n",
      "\u001b[1;32m   1709\u001b[0m }\n",
      "\u001b[1;32m   1710\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:2040\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   2036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n",
      "\u001b[1;32m   2037\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;32m   2038\u001b[0m ):\n",
      "\u001b[1;32m   2039\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n",
      "\u001b[0;32m-> 2040\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   2041\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n",
      "\u001b[1;32m   2042\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n",
      "\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32m    916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[1;32m    917\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n",
      "\u001b[1;32m    918\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n",
      "\u001b[0;32m--> 919\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n",
      "\u001b[1;32m    921\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    922\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "\u001b[1;32m    132\u001b[0m   (concrete_function,\n",
      "\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n",
      "\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n",
      "\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n",
      "\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n",
      "\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n",
      "\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n",
      "\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n",
      "\u001b[1;32m   1748\u001b[0m     args,\n",
      "\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n",
      "\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n",
      "\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n",
      "\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n",
      "\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n",
      "\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n",
      "\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n",
      "\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n",
      "\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data.repeat(),\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=val_data,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps,\n",
    "                    callbacks=[\n",
    "                        # decay_callback,\n",
    "                        csv_logger,\n",
    "                        create_model_checkpoint(model_name = 'capgen', save_dir = 'checkpoints', monitor = 'masked_acc'),\n",
    "                        tensorboard_callback\n",
    "                                ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcyou.plot import plot_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m plot_history(\u001b[43mhistory\u001b[49m,plot \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmasked_acc\u001b[39m\u001b[38;5;124m'\u001b[39m], split \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m], )\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_history(history,plot = ['loss','masked_acc'], split = ['train','val'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs/gradient_tape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(f'saved_model/best-{datetime.now()}-{EPOCHS}.h5')\n",
    "# model.save_weights(f'model_weights/best_so_far_final/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la -h 'saved_model/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_data.take(1))\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppred = tf.argmax(pred, axis = -1)\n",
    "print(ppred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ppred:\n",
    "    print(tf.strings.join(id_to_word(i), ' ').numpy())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_new",
   "language": "python",
   "name": "tf_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
