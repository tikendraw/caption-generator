{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tikendraw/caption-generator/blob/main/train_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    os.system('git clone https://github.com/tikendraw/caption-generator.git -q')\n",
        "    os.chdir('caption-generator')\n",
        "\n",
        "\n",
        "if not os.path.exists('funcyou'):\n",
        "\tos.system('git clone https://github.com/tikendraw/funcyou -q')\n",
        "\n",
        "os.system('pip install funcyou/.')"
      ],
      "metadata": {
        "id": "UPqWBnBr3qyC",
        "outputId": "62da8d48-9696-47a4-ae3c-0db9425e8a0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install funcyou/."
      ],
      "metadata": {
        "id": "n5cASyj73_nu",
        "outputId": "4d3979e6-0d5b-40de-c472-032da8229a28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'another model.py'\t\t   image-caption-generator-deep-learning.ipynb\n",
            " caption-generator\t\t   libdevice.10.bc\n",
            " captiongenerator_notebook.ipynb   local_config_cuda\n",
            " code.txt\t\t\t   main.py\n",
            " config.py\t\t\t   model.py\n",
            " data\t\t\t\t   preprocessing.py\n",
            " embedding\t\t\t   __pycache__\n",
            " funcyou\t\t\t   train_notebook.ipynb\n",
            " get_data.py\t\t\t   utils.py\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing ./funcyou\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from funcyou==1.0.0) (3.7.1)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (from funcyou==1.0.0) (3.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->funcyou==1.0.0) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->funcyou==1.0.0) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->funcyou==1.0.0) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->funcyou==1.0.0) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->funcyou==1.0.0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->funcyou==1.0.0) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->funcyou==1.0.0) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->funcyou==1.0.0) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->funcyou==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->funcyou==1.0.0) (1.16.0)\n",
            "Building wheels for collected packages: funcyou\n",
            "  Building wheel for funcyou (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for funcyou: filename=funcyou-1.0.0-py3-none-any.whl size=10314 sha256=a40acc3d7975b5366880b55d22760ab30d59b49808120268b70a11881d61929b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_xe43ouc/wheels/82/48/fc/74dcbb32089fecdd2b516b6b61928ed33c3e1ab25c126e9e9e\n",
            "Successfully built funcyou\n",
            "Installing collected packages: funcyou\n",
            "  Attempting uninstall: funcyou\n",
            "    Found existing installation: funcyou 1.0.0\n",
            "    Uninstalling funcyou-1.0.0:\n",
            "      Successfully uninstalled funcyou-1.0.0\n",
            "Successfully installed funcyou-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPhVMf_b419N",
        "outputId": "934a5a3f-3ac0-413e-87af-5ea1e2b072be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94668760/94668760 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random, math\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "import datetime\n",
        "import sys\n",
        "from functools import cache\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import regex as re\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocessing\n",
        "from tensorflow.keras.layers import (\n",
        "    TextVectorization, Embedding, LSTM, GRU, Bidirectional, TimeDistributed, Dense, Attention, MultiHeadAttention, Flatten, Dropout,\n",
        "    Concatenate, Activation, GlobalAveragePooling2D\n",
        "    )\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Input, Dense, Dropout, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import array_to_img, img_to_array\n",
        "import string\n",
        "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, TensorBoard\n",
        "from model import LearningRateDecayCallback, get_model, masked_acc, masked_loss\n",
        "from preprocessing import preprocess_text, embedding_matrix_creater, mapper, clean_words, clean_df\n",
        "from utils import create_model_checkpoint\n",
        "\n",
        "from config import config\n",
        "\n",
        "from get_data import download_dataset\n",
        "from funcyou.dataset import download_kaggle_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KdH2ocgf5DVi"
      },
      "outputs": [],
      "source": [
        "seed_value = 12321\n",
        "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "\n",
        "BATCH_SIZE =    config.BATCH_SIZE\n",
        "IMG_SIZE =      config.IMG_SIZE\n",
        "CHANNELS =      config.CHANNELS\n",
        "IMG_SHAPE =     config.IMG_SHAPE\n",
        "MAX_LEN =       config.MAX_LEN\n",
        "EPOCHS =        config.EPOCHS\n",
        "LEARNING_RATE = config.LEARNING_RATE\n",
        "UNITS =         config.UNITS\n",
        "raw_caption_file =  config.raw_caption_file\n",
        "caption_file =  config.caption_file\n",
        "image_dir =     config.image_dir\n",
        "glove_path =    config.glove_path\n",
        "TEST_SIZE =     config.TEST_SIZE\n",
        "VAL_SIZE=       config.VAL_SIZE\n",
        "EMBEDDING_DIMENSION =   config.EMBEDDING_DIMENSION "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "A3qtMoVA_lf_"
      },
      "outputs": [],
      "source": [
        "pathh = '/content/kaggle.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wi7t3Bs5KMz",
        "outputId": "90375520-20c5-49b4-84f0-818edb5fd8f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "kaggle datasets download -d hsankesara/flickr-image-dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100B [01:05, 1.54B/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded.\n",
            "Extracting...\n",
            "Moving...\n",
            "Done\n",
            "Cleaned.\n"
          ]
        }
      ],
      "source": [
        "if 'google.colab' in sys.modules:\n",
        "    download_dataset(pathh)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf flickr30k_images"
      ],
      "metadata": {
        "id": "g8Lwt1Oy7TC0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2RsNzwVEoIU"
      },
      "source": [
        "# Reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "IxFlSCnqDIxq",
        "outputId": "3ea1d4f8-17b1-4f1e-863a-e4591b005971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 158914 entries, 0 to 158913\n",
            "Data columns (total 6 columns):\n",
            " #   Column          Non-Null Count   Dtype \n",
            "---  ------          --------------   ----- \n",
            " 0   Unnamed: 0      158914 non-null  int64 \n",
            " 1   image_name      158914 non-null  object\n",
            " 2   comment_number  158914 non-null  int64 \n",
            " 3   comment         158914 non-null  object\n",
            " 4   word_length     158914 non-null  int64 \n",
            " 5   image_path      158914 non-null  object\n",
            "dtypes: int64(3), object(3)\n",
            "memory usage: 7.3+ MB\n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0      image_name  comment_number  \\\n",
              "0           0  1000092795.jpg               0   \n",
              "1           1  1000092795.jpg               1   \n",
              "2           2  1000092795.jpg               2   \n",
              "3           3  1000092795.jpg               3   \n",
              "4           4  1000092795.jpg               4   \n",
              "\n",
              "                                             comment  word_length  \\\n",
              "0  startseq Two young guys with shaggy hair look ...           17   \n",
              "1  startseq Two young White males are outside nea...           11   \n",
              "2  startseq Two men in green shirts are standing ...           11   \n",
              "3  startseq A man in a blue shirt standing in a g...           11   \n",
              "4    startseq Two friends enjoy time together endseq            7   \n",
              "\n",
              "                              image_path  \n",
              "0  input/flickr30k/images/1000092795.jpg  \n",
              "1  input/flickr30k/images/1000092795.jpg  \n",
              "2  input/flickr30k/images/1000092795.jpg  \n",
              "3  input/flickr30k/images/1000092795.jpg  \n",
              "4  input/flickr30k/images/1000092795.jpg  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9b6ee3b-c6b0-4be5-a469-40576d07825e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>image_name</th>\n",
              "      <th>comment_number</th>\n",
              "      <th>comment</th>\n",
              "      <th>word_length</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1000092795.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>startseq Two young guys with shaggy hair look ...</td>\n",
              "      <td>17</td>\n",
              "      <td>input/flickr30k/images/1000092795.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1000092795.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>startseq Two young White males are outside nea...</td>\n",
              "      <td>11</td>\n",
              "      <td>input/flickr30k/images/1000092795.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1000092795.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>startseq Two men in green shirts are standing ...</td>\n",
              "      <td>11</td>\n",
              "      <td>input/flickr30k/images/1000092795.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1000092795.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>startseq A man in a blue shirt standing in a g...</td>\n",
              "      <td>11</td>\n",
              "      <td>input/flickr30k/images/1000092795.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1000092795.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>startseq Two friends enjoy time together endseq</td>\n",
              "      <td>7</td>\n",
              "      <td>input/flickr30k/images/1000092795.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9b6ee3b-c6b0-4be5-a469-40576d07825e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9b6ee3b-c6b0-4be5-a469-40576d07825e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9b6ee3b-c6b0-4be5-a469-40576d07825e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df = pd.read_csv(caption_file)\n",
        "\n",
        "print(df.info())\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVORBQxSE2tn",
        "outputId": "fe9ba702-3994-4f43-8c6d-8aa68a598133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31783, 6)\n"
          ]
        }
      ],
      "source": [
        "df = df[df.comment_number == 1]\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTMyFjg3C4mo"
      },
      "source": [
        "# Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Tg2RRXBWC3pQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "#tokenizer\n",
        "tokenizer = TextVectorization(standardize=preprocess_text)\n",
        "tokenizer.adapt(df['comment'])\n",
        "\n",
        "\n",
        "word_to_id = tf.keras.layers.StringLookup(vocabulary=tokenizer.get_vocabulary(), mask_token='', oov_token='[UNK]')\n",
        "id_to_word = tf.keras.layers.StringLookup(vocabulary=tokenizer.get_vocabulary(), mask_token='', oov_token='[UNK]', invert=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te1Hw6gq4hIR",
        "outputId": "9b8ed9ff-5e58-40fc-e8d4-4c9a23f2ebf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle datasets download -d watts2/glove6b50dtxt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100B [00:02, 49.9B/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 3586\n",
            "Number of validation samples: 199\n",
            "Number of test samples: 189\n",
            "Vocabulary size: 7653\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "#GLOVE embedding\n",
        "glove_api_command = 'kaggle datasets download -d watts2/glove6b50dtxt'\n",
        "glove_url = 'https://www.kaggle.com/datasets/watts2/glove6b50dtxt'\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "\n",
        "    download_kaggle_dataset(glove_api_command)\n",
        "    os.makedirs('embedding', exist_ok = True)\n",
        "    shutil.move('glove6b50dtxt.zip', 'embedding/glove.6B.50d.zip',)\n",
        "\n",
        "\n",
        "# creating embedding matrix\n",
        "word_dict = {word: i for i, word in enumerate(tokenizer.get_vocabulary())}\n",
        "\n",
        "# Creating embedding matrix\n",
        "embedding_matrix = embedding_matrix_creater(EMBEDDING_DIMENSION, word_index=word_dict)\n",
        "\n",
        "# # Saving embedding_matrix for further use\n",
        "# np.save(\"./embedding/embedding_matrix.npy\", embedding_matrix, allow_pickle=True)\n",
        "# # compressing\n",
        "# ZipFile(\"embedding_matrix.zip\", mode=\"w\").write(\n",
        "#     \"./embedding/embedding_matrix.npy\")\n",
        "\n",
        "\n",
        "# load image model\n",
        "resnet = tf.keras.applications.ResNet50V2(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=tf.keras.layers.Input(shape=IMG_SHAPE))\n",
        "\n",
        "resnet.trainable = False\n",
        "\n",
        "\n",
        "# Creating dataset\n",
        "TEST_SIZE = config.TEST_SIZE\n",
        "VAL_SIZE =  config.VAL_SIZE\n",
        "\n",
        "train, val = train_test_split(\n",
        "    df[['image_path', 'comment']],  test_size=VAL_SIZE, random_state=11)\n",
        "train, test = train_test_split(\n",
        "    train[['image_path', 'comment']],  test_size=TEST_SIZE, random_state=11)\n",
        "\n",
        "\n",
        "train_data = tf.data.Dataset.from_tensor_slices((train.image_path, train.comment))\n",
        "test_data = tf.data.Dataset.from_tensor_slices((test.image_path, test.comment))\n",
        "val_data = tf.data.Dataset.from_tensor_slices((val.image_path, val.comment))\n",
        "\n",
        "\n",
        "train_data = train_data.map(lambda x,y:mapper(x, y, tokenizer)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_data =   test_data.map(lambda x,y:mapper(x, y, tokenizer)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_data =     val_data.map(lambda x,y:mapper(x, y, tokenizer)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# resnet_output_flattened_shape = 8*8*2048\n",
        "\n",
        "print(\"Number of training samples: %d\" %\n",
        "      tf.data.experimental.cardinality(train_data))\n",
        "print(\"Number of validation samples: %d\" %\n",
        "      tf.data.experimental.cardinality(val_data))\n",
        "print(\"Number of test samples: %d\" %\n",
        "      tf.data.experimental.cardinality(test_data))\n",
        "\n",
        "VOCAB_SIZE = tokenizer.vocabulary_size()\n",
        "print(\"Vocabulary size: %d\" % VOCAB_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bhgJTkV93Lbe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hSSztQsfRuzJ",
        "outputId": "5eef9e11-8775-4489-b2d0-18af0a3d03b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 50)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 50, 50)       382650      ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 50, 16),     4288        ['embedding[0][0]']              \n",
            "                                 (None, 16),                                                      \n",
            "                                 (None, 16)]                                                      \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 2048)]       0           []                               \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 50, 16)       0           ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 800)          1639200     ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 50, 16)       2112        ['dropout[0][0]',                \n",
            "                                                                  'lstm[0][1]',                   \n",
            "                                                                  'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " tf.reshape (TFOpLambda)        (None, 50, 16)       0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 50, 16)       0           ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            " attention (Attention)          (None, 50, 16)       0           ['tf.reshape[0][0]',             \n",
            "                                                                  'dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " attention_1 (Attention)        (None, 50, 16)       0           ['dropout_1[0][0]',              \n",
            "                                                                  'tf.reshape[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 50, 64)       0           ['tf.reshape[0][0]',             \n",
            "                                                                  'dropout_1[0][0]',              \n",
            "                                                                  'attention[0][0]',              \n",
            "                                                                  'attention_1[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 50, 64)       0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 50, 100)      6500        ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 50, 100)      10100       ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 50, 7653)     772953      ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,817,803\n",
            "Trainable params: 2,435,153\n",
            "Non-trainable params: 382,650\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = get_model(embedding_matrix, VOCAB_SIZE)\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "              loss=masked_loss,\n",
        "              metrics=[masked_acc, masked_loss])\n",
        "\n",
        "\n",
        "# model = tf.keras.models.load_model('/content/drive/MyDrive/cap-gen/2023-05-14 08:04:36.705364-30.tf')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VrFvq8baLFDz"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Example usage\n",
        "initial_lr = LEARNING_RATE\n",
        "decay_rate = -0.001\n",
        "decay_steps = 2\n",
        "\n",
        "decay_callback = LearningRateDecayCallback(initial_lr, decay_rate, decay_steps)\n",
        "\n",
        "os.makedirs('log', exist_ok=True)\n",
        "csv_logger = CSVLogger('./log/training.log')\n",
        "tb_callback = tf.keras.callbacks.TensorBoard('./logs', update_freq=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0nz0_27LUSL",
        "outputId": "bf8e9211-6fa6-4ae8-bb98-9c80c64c976b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.01\n"
          ]
        }
      ],
      "source": [
        "print(initial_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH--P_BE4qSV",
        "outputId": "065b9805-1d36-4554-9e46-658a4f943cef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1195 66\n",
            "119 13\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "print(len(train_data) // EPOCHS, len(val_data) // EPOCHS)\n",
        "\n",
        "steps_per_epoch = int(0.1*(len(train_data) / EPOCHS))\n",
        "validation_steps =  int(.2*(len(val_data) / EPOCHS))\n",
        "print(steps_per_epoch, validation_steps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac3qO85h4qNE",
        "outputId": "630efa8c-3dce-46f4-9cdd-fedda1317108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "119/119 [==============================] - ETA: 0s - loss: 20.1196 - masked_acc: 4.0578e-04 - masked_loss: 20.1200"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r119/119 [==============================] - 268s 2s/step - loss: 20.1196 - masked_acc: 4.0578e-04 - masked_loss: 20.1200 - val_loss: 21.1002 - val_masked_acc: 0.0000e+00 - val_masked_loss: 21.1075\n",
            "Epoch 2/3\n",
            "119/119 [==============================] - 244s 2s/step - loss: 20.5730 - masked_acc: 8.1453e-05 - masked_loss: 20.5780 - val_loss: 21.1443 - val_masked_acc: 0.0000e+00 - val_masked_loss: 21.1778\n",
            "Epoch 3/3\n",
            "119/119 [==============================] - 212s 2s/step - loss: 20.7125 - masked_acc: 0.0000e+00 - masked_loss: 20.7103 - val_loss: 21.0854 - val_masked_acc: 0.0000e+00 - val_masked_loss: 21.1121\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_data,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=val_data,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    validation_steps=validation_steps,\n",
        "                    callbacks=[\n",
        "                        decay_callback,\n",
        "                        csv_logger, create_model_checkpoint(model_name = 'capgen', save_dir = 'checkpoints', monitor = 'masked_acc')\n",
        "                                ]\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVDBU9sFQ4bB",
        "outputId": "e6a46a4b-7a11-4ddb-8222-f51ab57fadc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXqqH-Yd4qKP",
        "outputId": "c0e01f14-cab7-486c-dbec-9bcf0daf88db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 6s 6s/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# model.save(f'/content/drive/MyDrive/cap-gen/{datetime.datetime.now()}-{EPOCHS}.tf')\n",
        "\n",
        "pred = model.predict(test_data.take(1))\n",
        "# print(pred.shape)\n",
        "\n",
        "# start_token_id = word_to_id('startseq') \n",
        "# end_token_id = word_to_id('endseq') \n",
        "\n",
        "\n",
        "\n",
        "# aa = generate_caption(random_image_path, model, tokenizer)\n",
        "# print(aa)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TaXI3HM4qHV",
        "outputId": "0330a2b6-417b-465c-b70e-d28d54b71d10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 50, 7653)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SEgrpR5C4qEN"
      },
      "outputs": [],
      "source": [
        "from preprocessing import tokens_to_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "START_TOKEN = 'startseq'\n",
        "END_TOKEN = 'endseq'\n"
      ],
      "metadata": {
        "id": "t8Kg89PA8yWK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokens_to_text(tokens):\n",
        "    words = id_to_word(tokens)\n",
        "    result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "    result = tf.strings.regex_replace(result, f'^ *{START_TOKEN} *', '')\n",
        "    result = tf.strings.regex_replace(result, f' *{END_TOKEN} *$', '')\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "Bz1oGEdS8v7Q"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predd = tf.argmax(pred, axis = -1)\n",
        "predd.shape"
      ],
      "metadata": {
        "id": "1jH685-1-qhI",
        "outputId": "1ab2e204-aac3-4a01-d21b-86aba63ec608",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([8, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "6HzwY_t14qBZ"
      },
      "outputs": [],
      "source": [
        "rr = tokens_to_text(predd)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rr.shape"
      ],
      "metadata": {
        "id": "OUKOmqDW9VP-",
        "outputId": "7bb7ca06-7534-4c65-f163-4a8d88a5ec0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([8])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for (img, txt_in), txt_out in test_data.take(1):\n",
        "    print(img.shape)"
      ],
      "metadata": {
        "id": "uoATojqI9uu-",
        "outputId": "c5e75d90-04ae-4d54-8927-ef6179f515ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "id": "H88_RgYW-Cba",
        "outputId": "d20c1075-4510-422f-e898-0fcc5f54043d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   image_path  \\\n",
              "115745  input/flickr30k/images/4761236916.jpg   \n",
              "97590   input/flickr30k/images/4388731466.jpg   \n",
              "114665  input/flickr30k/images/4745027152.jpg   \n",
              "9786    input/flickr30k/images/1557838421.jpg   \n",
              "28360   input/flickr30k/images/2414352262.jpg   \n",
              "\n",
              "                                                  comment  \n",
              "115745  startseq A dark haired child in swimwear laugh...  \n",
              "97590   startseq Two dark haired men in orange shirts ...  \n",
              "114665  startseq A young lady is colorfully dressed in...  \n",
              "9786    startseq Two dogs wrestle with each other with...  \n",
              "28360   startseq young girl in winter coat jumping off...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce993c67-0906-462b-bb3d-3e7684b6e8d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>115745</th>\n",
              "      <td>input/flickr30k/images/4761236916.jpg</td>\n",
              "      <td>startseq A dark haired child in swimwear laugh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97590</th>\n",
              "      <td>input/flickr30k/images/4388731466.jpg</td>\n",
              "      <td>startseq Two dark haired men in orange shirts ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114665</th>\n",
              "      <td>input/flickr30k/images/4745027152.jpg</td>\n",
              "      <td>startseq A young lady is colorfully dressed in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9786</th>\n",
              "      <td>input/flickr30k/images/1557838421.jpg</td>\n",
              "      <td>startseq Two dogs wrestle with each other with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28360</th>\n",
              "      <td>input/flickr30k/images/2414352262.jpg</td>\n",
              "      <td>startseq young girl in winter coat jumping off...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce993c67-0906-462b-bb3d-3e7684b6e8d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce993c67-0906-462b-bb3d-3e7684b6e8d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce993c67-0906-462b-bb3d-3e7684b6e8d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "s-OtR5Ma4p9x",
        "outputId": "386c4aa1-cb98-4237-f429-91cef71c1c59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8,), dtype=string, numpy=\n",
              "array([b'power power power power power power power power power power power power power power power arts arts expressing power conducts power arts power besides learn rolling arts power arts power impeach rolling rolling server trudging power releasing besides lightly rolling trudging impeach conducts wardrobe power power impeach impeach power besides',\n",
              "       b'power power power power power power power power power power power power power power power power arts expressing power conducts power arts power besides teams rolling arts power arts power impeach rolling wardrobe server trudging power couples besides lightly rolling trudging impeach rolling wardrobe power power impeach impeach power besides',\n",
              "       b'power power power power power power power power power power power power power power power arts arts expressing power conducts power arts power besides power rolling arts power arts power impeach conducts rolling server rolling power besides besides write rolling trudging impeach conducts wardrobe power power impeach impeach power besides',\n",
              "       b'power power power power power power power power power power power power power power power arts arts expressing power conducts power arts power power teams rolling arts power arts power impeach rolling lightly server conducts power power besides lightly rolling trudging impeach arts wardrobe power power conducts impeach power await',\n",
              "       b'power power power power power power power power power power power power power power power arts arts expressing power conducts power arts power besides teams rolling arts power arts power impeach rolling lightly server trudging power besides besides expressing rolling trudging impeach arts wardrobe power power conducts impeach power besides',\n",
              "       b'power power power power power power power power power power power power power power power power power expressing power conducts power arts power besides teams rolling arts power arts power impeach rolling wardrobe server trudging power couples besides lightly rolling trudging impeach conducts wardrobe power power conducts impeach power besides',\n",
              "       b'power power power power power power power power power power power power power power power arts arts expressing power conducts power arts power power sun rolling arts power arts power impeach rolling rolling server trudging power besides besides power rolling trudging impeach rolling wardrobe power power impeach impeach power arts',\n",
              "       b'power power power power power power power power power power power power power power power power power expressing power conducts power arts power besides sitar rolling arts power arts power impeach rolling lightly server trudging power besides besides lightly rolling trudging impeach arts wardrobe power power conducts impeach power besides'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "rr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from preprocessing import load_images_now"
      ],
      "metadata": {
        "id": "QX164-rr_P98"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_token = START_TOKEN\n",
        "end_token = END_TOKEN"
      ],
      "metadata": {
        "id": "liRul0Ne_Z2d"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def generate_caption(image_path, model, tokenizer, beam_size=5):\n",
        "#     ii = plt.imread(image_path)\n",
        "#     plt.imshow(ii)\n",
        "\n",
        "#     features = load_images_now(image_path)\n",
        "#     features = tf.reshape(features, (1, features.shape[0]))\n",
        "\n",
        "#     beams = [[start_token]] * beam_size\n",
        "\n",
        "#     for _ in range(MAX_LEN):\n",
        "#         for i, beam in enumerate(beams):\n",
        "#             sequence = tokenizer([beam.decode('utf-8')])\n",
        "#             sequence = tf.pad(sequence, [[0, 0], [0, MAX_LEN - tf.shape(sequence)[1]]])\n",
        "\n",
        "#             logits = model.predict([features, sequence], verbose = 0)\n",
        "#             next_word_idx = tf.argmax(logits, axis=-1)\n",
        "\n",
        "#             next_word = id_to_word(next_word_idx.numpy()[0])\n",
        "\n",
        "#             beams[i].append(next_word)\n",
        "\n",
        "#             beams.sort(key=lambda x: x[-1], reverse=True)\n",
        "\n",
        "#             beams = beams[:beam_size]\n",
        "\n",
        "#         caption = beams[0]\n",
        "#     return ' '.join(caption[1:])"
      ],
      "metadata": {
        "id": "C_WTYK-39Z9n"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_caption(image_path):\n",
        "\n",
        "  # Load the image and resize it to 224x224 pixels.\n",
        "  image = tf.io.read_file(image_path)\n",
        "  image = tf.image.decode_jpeg(image, channels=CHANNELS)\n",
        "  image = tf.image.resize(image, (224, 224))\n",
        "\n",
        "  # Get the image features from the ResNet50V2 model.\n",
        "  image_features = resnet(image)\n",
        "\n",
        "  # Get the start and end tokens.\n",
        "  start_token = tf.constant([VOCAB_SIZE - 1], dtype=tf.int32)\n",
        "  end_token = tf.constant([VOCAB_SIZE], dtype=tf.int32)\n",
        "\n",
        "  # Initialize the decoder state.\n",
        "  decoder_state = encoder.initialize_state(image_features)\n",
        "\n",
        "  # Initialize the output sequence.\n",
        "  output_sequence = []\n",
        "\n",
        "  # Generate the caption.\n",
        "  for i in range(MAX_LEN):\n",
        "\n",
        "    # Get the next word.\n",
        "    next_word_logits, decoder_state = decoder(image_features, decoder_state)\n",
        "    next_word = tf.argmax(next_word_logits, axis=1)\n",
        "\n",
        "    # If the next word is the end token, stop generating.\n",
        "    if next_word == end_token:\n",
        "      break\n",
        "\n",
        "    # Add the next word to the output sequence.\n",
        "    output_sequence.append(next_word)\n",
        "\n",
        "  # Convert the output sequence to a string.\n",
        "  output_caption = tokenizer.inverse_transform(output_sequence)\n",
        "\n",
        "  return output_caption"
      ],
      "metadata": {
        "id": "B635Fa78A-9h"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_img_path = test['image_path'].sample(1).values[0]"
      ],
      "metadata": {
        "id": "RNDAMqYZ_No2"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rr = generate_caption(random_img_path, model, tokenizer)\n",
        "rr"
      ],
      "metadata": {
        "id": "YOV6kfvA_sFi",
        "outputId": "cd3e2bea-8a8e-481d-af74-df371a1cebe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-13b9f6b7bc26>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_caption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_img_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-a1655cc68d06>\u001b[0m in \u001b[0;36mgenerate_caption\u001b[0;34m(image_path, model, tokenizer)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Loop to generate the caption one word at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mpredicted_word_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model' (type Functional).\n    \n    Input 0 of layer \"lstm\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 50)\n    \n    Call arguments received by layer 'model' (type Functional):\n       inputs=('tf.Tensor(shape=(None, 2048), dtype=float32)', 'tf.Tensor(shape=(None,), dtype=int32)')\n       training=False\n       mask=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vQgQAlZo_5Tq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "tf_new",
      "language": "python",
      "name": "tf_new"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}