{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tikendraw/caption-generator/blob/main/train_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPqWBnBr3qyC",
        "outputId": "62da8d48-9696-47a4-ae3c-0db9425e8a0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing ./funcyou\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: matplotlib in /home/t/miniconda3/envs/tf_new/lib/python3.9/site-packages (from funcyou==1.0.0) (3.6.3)\n",
            "Requirement already satisfied: wget in /home/t/miniconda3/envs/tf_new/lib/python3.9/site-packages (from funcyou==1.0.0) (3.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/t/miniconda3/envs/tf_new/lib/python3.9/site-packages (from matplotlib->funcyou==1.0.0) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/t/miniconda3/envs/tf_new/lib/python3.9/site-packages (from matplotlib->funcyou==1.0.0) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/t/miniconda3/envs/tf_new/lib/python3.9/site-packages (from matplotlib->funcyou==1.0.0) (4.38.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/t/miniconda3/envs/tf_new/lib/python3.9/site-packages (from matplotlib->funcyou==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/t/miniconda3/envs/tf_new/lib/python3.9/site-packages (from matplotlib->funcyou==1.0.0) (23.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/t/miniconda3/envs/tf_new/lib/python3.9/site-packages (from matplotlib->funcyou==1.0.0) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /home/t/miniconda3/envs/tf_new/lib/python3.9/site-packages (from matplotlib->funcyou==1.0.0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/t/miniconda3/envs/tf_new/lib/python3.9/site-packages (from matplotlib->funcyou==1.0.0) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.19 in /home/t/miniconda3/envs/tf_new/lib/python3.9/site-packages (from matplotlib->funcyou==1.0.0) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /home/t/miniconda3/envs/tf_new/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->funcyou==1.0.0) (1.16.0)\n",
            "Building wheels for collected packages: funcyou\n",
            "  Building wheel for funcyou (setup.py): started\n",
            "  Building wheel for funcyou (setup.py): finished with status 'done'\n",
            "  Created wheel for funcyou: filename=funcyou-1.0.0-py3-none-any.whl size=10306 sha256=d205f75ec5be00a243eacd902cabefdb174193f6d61559865e79ee93a3eef3f7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qeuuyjhq/wheels/de/8f/12/1d39c4f61fb2d82559e7785cfe1f892026a0b11a36f2827389\n",
            "Successfully built funcyou\n",
            "Installing collected packages: funcyou\n",
            "  Attempting uninstall: funcyou\n",
            "    Found existing installation: funcyou 1.0.0\n",
            "    Uninstalling funcyou-1.0.0:\n",
            "      Successfully uninstalled funcyou-1.0.0\n",
            "Successfully installed funcyou-1.0.0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    os.system('git clone https://github.com/tikendraw/caption-generator.git -q')\n",
        "    os.chdir('caption-generator')\n",
        "\n",
        "\n",
        "if not os.path.exists('funcyou'):\n",
        "\tos.system('git clone https://github.com/tikendraw/funcyou -q')\n",
        "\n",
        "os.system('pip install funcyou/.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5cASyj73_nu",
        "outputId": "4d3979e6-0d5b-40de-c472-032da8229a28"
      },
      "outputs": [],
      "source": [
        "# ! pip install funcyou/."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPhVMf_b419N",
        "outputId": "934a5a3f-3ac0-413e-87af-5ea1e2b072be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-15 22:04:22.690321: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-15 22:04:23.867546: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-15 22:04:26.047909: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-15 22:04:26.090640: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-15 22:04:26.090862: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-15 22:04:26.091903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-15 22:04:26.092277: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-15 22:04:26.092438: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-15 22:04:27.398916: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-15 22:04:27.399131: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-15 22:04:27.399280: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-15 22:04:27.399390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2201 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
            "[nltk_data] Downloading package punkt to /home/t/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random, math\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "import datetime\n",
        "import sys\n",
        "from functools import cache\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import regex as re\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocessing\n",
        "from tensorflow.keras.layers import (\n",
        "    TextVectorization, Embedding, LSTM, GRU, Bidirectional, TimeDistributed, Dense, Attention, MultiHeadAttention, Flatten, Dropout,\n",
        "    Concatenate, Activation, GlobalAveragePooling2D\n",
        "    )\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Input, Dense, Dropout, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import array_to_img, img_to_array\n",
        "import string\n",
        "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, TensorBoard\n",
        "from model import LearningRateDecayCallback, get_model, masked_acc, masked_loss\n",
        "from preprocessing import preprocess_text, embedding_matrix_creater, mapper, clean_words, clean_df\n",
        "from utils import create_model_checkpoint\n",
        "\n",
        "from config import config\n",
        "\n",
        "from get_data import download_dataset\n",
        "from funcyou.dataset import download_kaggle_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KdH2ocgf5DVi"
      },
      "outputs": [],
      "source": [
        "seed_value = 12321\n",
        "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "\n",
        "BATCH_SIZE =    config.BATCH_SIZE\n",
        "IMG_SIZE =      config.IMG_SIZE\n",
        "CHANNELS =      config.CHANNELS\n",
        "IMG_SHAPE =     config.IMG_SHAPE\n",
        "MAX_LEN =       config.MAX_LEN\n",
        "EPOCHS =        config.EPOCHS\n",
        "LEARNING_RATE = config.LEARNING_RATE\n",
        "UNITS =         config.UNITS\n",
        "raw_caption_file =  config.raw_caption_file\n",
        "caption_file =  config.caption_file\n",
        "image_dir =     config.image_dir\n",
        "glove_path =    config.glove_path\n",
        "TEST_SIZE =     config.TEST_SIZE\n",
        "VAL_SIZE=       config.VAL_SIZE\n",
        "EMBEDDING_DIMENSION =   config.EMBEDDING_DIMENSION "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "A3qtMoVA_lf_"
      },
      "outputs": [],
      "source": [
        "pathh = '/content/kaggle.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wi7t3Bs5KMz",
        "outputId": "90375520-20c5-49b4-84f0-818edb5fd8f8"
      },
      "outputs": [],
      "source": [
        "if 'google.colab' in sys.modules:\n",
        "    download_dataset(pathh)\n",
        "    # ! rm -rf flickr30k_images\n",
        "\n",
        "#GLOVE embedding\n",
        "glove_api_command = 'kaggle datasets download -d watts2/glove6b50dtxt'\n",
        "glove_url = 'https://www.kaggle.com/datasets/watts2/glove6b50dtxt'\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "\n",
        "    download_kaggle_dataset(glove_api_command)\n",
        "    os.makedirs('embedding', exist_ok = True)\n",
        "    shutil.move('glove6b50dtxt.zip', 'embedding/glove.6B.50d.zip',)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "S2RsNzwVEoIU"
      },
      "source": [
        "# Reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "IxFlSCnqDIxq",
        "outputId": "3ea1d4f8-17b1-4f1e-863a-e4591b005971"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 158914 entries, 0 to 158913\n",
            "Data columns (total 6 columns):\n",
            " #   Column          Non-Null Count   Dtype \n",
            "---  ------          --------------   ----- \n",
            " 0   Unnamed: 0      158914 non-null  int64 \n",
            " 1   image_name      158914 non-null  object\n",
            " 2   comment_number  158914 non-null  int64 \n",
            " 3   comment         158914 non-null  object\n",
            " 4   word_length     158914 non-null  int64 \n",
            " 5   image_path      158914 non-null  object\n",
            "dtypes: int64(3), object(3)\n",
            "memory usage: 7.3+ MB\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>image_name</th>\n",
              "      <th>comment_number</th>\n",
              "      <th>comment</th>\n",
              "      <th>word_length</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1000092795.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>startseq Two young guys with shaggy hair look ...</td>\n",
              "      <td>17</td>\n",
              "      <td>input/flickr30k/images/1000092795.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1000092795.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>startseq Two young White males are outside nea...</td>\n",
              "      <td>11</td>\n",
              "      <td>input/flickr30k/images/1000092795.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1000092795.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>startseq Two men in green shirts are standing ...</td>\n",
              "      <td>11</td>\n",
              "      <td>input/flickr30k/images/1000092795.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1000092795.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>startseq A man in a blue shirt standing in a g...</td>\n",
              "      <td>11</td>\n",
              "      <td>input/flickr30k/images/1000092795.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1000092795.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>startseq Two friends enjoy time together endseq</td>\n",
              "      <td>7</td>\n",
              "      <td>input/flickr30k/images/1000092795.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0      image_name  comment_number   \n",
              "0           0  1000092795.jpg               0  \\\n",
              "1           1  1000092795.jpg               1   \n",
              "2           2  1000092795.jpg               2   \n",
              "3           3  1000092795.jpg               3   \n",
              "4           4  1000092795.jpg               4   \n",
              "\n",
              "                                             comment  word_length   \n",
              "0  startseq Two young guys with shaggy hair look ...           17  \\\n",
              "1  startseq Two young White males are outside nea...           11   \n",
              "2  startseq Two men in green shirts are standing ...           11   \n",
              "3  startseq A man in a blue shirt standing in a g...           11   \n",
              "4    startseq Two friends enjoy time together endseq            7   \n",
              "\n",
              "                              image_path  \n",
              "0  input/flickr30k/images/1000092795.jpg  \n",
              "1  input/flickr30k/images/1000092795.jpg  \n",
              "2  input/flickr30k/images/1000092795.jpg  \n",
              "3  input/flickr30k/images/1000092795.jpg  \n",
              "4  input/flickr30k/images/1000092795.jpg  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(caption_file)\n",
        "\n",
        "print(df.info())\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVORBQxSE2tn",
        "outputId": "fe9ba702-3994-4f43-8c6d-8aa68a598133"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(31783, 6)\n"
          ]
        }
      ],
      "source": [
        "df = df[df.comment_number == 1]\n",
        "print(df.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aTMyFjg3C4mo"
      },
      "source": [
        "# Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Tg2RRXBWC3pQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "#tokenizer\n",
        "tokenizer = TextVectorization(standardize=preprocess_text)\n",
        "tokenizer.adapt(df['comment'])\n",
        "\n",
        "\n",
        "word_to_id = tf.keras.layers.StringLookup(vocabulary=tokenizer.get_vocabulary(), mask_token='', oov_token='[UNK]')\n",
        "id_to_word = tf.keras.layers.StringLookup(vocabulary=tokenizer.get_vocabulary(), mask_token='', oov_token='[UNK]', invert=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te1Hw6gq4hIR",
        "outputId": "9b8ed9ff-5e58-40fc-e8d4-4c9a23f2ebf7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-15 22:04:43.325982: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'args_0' with dtype string\n",
            "\t [[{{node args_0}}]]\n",
            "2023-05-15 22:04:43.532010: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'args_0' with dtype string\n",
            "\t [[{{node args_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training samples: 3586\n",
            "Number of validation samples: 199\n",
            "Number of test samples: 189\n",
            "Vocabulary size: 7653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-15 22:04:43.759339: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'args_0' with dtype string\n",
            "\t [[{{node args_0}}]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# creating embedding matrix\n",
        "word_dict = {word: i for i, word in enumerate(tokenizer.get_vocabulary())}\n",
        "\n",
        "# Creating embedding matrix\n",
        "embedding_matrix = embedding_matrix_creater(EMBEDDING_DIMENSION, word_index=word_dict)\n",
        "\n",
        "# # Saving embedding_matrix for further use\n",
        "# np.save(\"./embedding/embedding_matrix.npy\", embedding_matrix, allow_pickle=True)\n",
        "# # compressing\n",
        "# ZipFile(\"embedding_matrix.zip\", mode=\"w\").write(\n",
        "#     \"./embedding/embedding_matrix.npy\")\n",
        "\n",
        "\n",
        "# load image model\n",
        "resnet = tf.keras.applications.ResNet50V2(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=tf.keras.layers.Input(shape=IMG_SHAPE))\n",
        "\n",
        "resnet.trainable = False\n",
        "\n",
        "\n",
        "# Creating dataset\n",
        "TEST_SIZE = config.TEST_SIZE\n",
        "VAL_SIZE =  config.VAL_SIZE\n",
        "\n",
        "train, val = train_test_split(\n",
        "    df[['image_path', 'comment']],  test_size=VAL_SIZE, random_state=11)\n",
        "train, test = train_test_split(\n",
        "    train[['image_path', 'comment']],  test_size=TEST_SIZE, random_state=11)\n",
        "\n",
        "\n",
        "train_data = tf.data.Dataset.from_tensor_slices((train.image_path, train.comment))\n",
        "test_data = tf.data.Dataset.from_tensor_slices((test.image_path, test.comment))\n",
        "val_data = tf.data.Dataset.from_tensor_slices((val.image_path, val.comment))\n",
        "\n",
        "\n",
        "train_data = train_data.map(lambda x,y:mapper(x, y, tokenizer)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_data =   test_data.map(lambda x,y:mapper(x, y, tokenizer)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_data =     val_data.map(lambda x,y:mapper(x, y, tokenizer)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# resnet_output_flattened_shape = 8*8*2048\n",
        "\n",
        "print(\"Number of training samples: %d\" %\n",
        "      tf.data.experimental.cardinality(train_data))\n",
        "print(\"Number of validation samples: %d\" %\n",
        "      tf.data.experimental.cardinality(val_data))\n",
        "print(\"Number of test samples: %d\" %\n",
        "      tf.data.experimental.cardinality(test_data))\n",
        "\n",
        "VOCAB_SIZE = tokenizer.vocabulary_size()\n",
        "print(\"Vocabulary size: %d\" % VOCAB_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bhgJTkV93Lbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_input:  (None, 2048)\n",
            "enc dropout:  (None, 2048)\n",
            "Dense:  (None, 800)\n",
            "reshape:  (None, 50, 16)\n",
            "txt_input:  (None, 50)\n",
            "text_embedding:  (None, 50, 50)\n",
            "encoder output:  (None, 50, 16)\n",
            "enc dropout:  (None, 50, 16)\n",
            "decoder output:  (None, 50, 16)\n",
            "decoder dropout:  (None, 50, 16)\n",
            "attention:  (None, 50, 16) (None, 50, 16)\n",
            "concat:  (None, 50, 64)\n",
            "concat dropout:  (None, 50, 64)\n",
            "Dense1:  (None, 50, 800)\n",
            "Dense2:  (None, 50, 800)\n",
            "Dense3_final:  (None, 50, 7653)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text_input (InputLayer)        [(None, 50)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 50, 50)       382650      ['text_input[0][0]']             \n",
            "                                                                                                  \n",
            " image_input (InputLayer)       [(None, 2048)]       0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 50, 16),     4288        ['embedding[0][0]']              \n",
            "                                 (None, 16),                                                      \n",
            "                                 (None, 16)]                                                      \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 2048)         0           ['image_input[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 50, 16)       0           ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 800)          1639200     ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 50, 16)       2112        ['dropout_1[0][0]',              \n",
            "                                                                  'lstm[0][1]',                   \n",
            "                                                                  'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " tf.reshape (TFOpLambda)        (None, 50, 16)       0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 50, 16)       0           ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            " attention (Attention)          (None, 50, 16)       0           ['tf.reshape[0][0]',             \n",
            "                                                                  'dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " attention_1 (Attention)        (None, 50, 16)       0           ['dropout_2[0][0]',              \n",
            "                                                                  'tf.reshape[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 50, 64)       0           ['tf.reshape[0][0]',             \n",
            "                                                                  'dropout_2[0][0]',              \n",
            "                                                                  'attention[0][0]',              \n",
            "                                                                  'attention_1[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 50, 64)       0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 50, 800)      52000       ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 50, 800)      640800      ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 50, 7653)     6130053     ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,851,103\n",
            "Trainable params: 8,468,453\n",
            "Non-trainable params: 382,650\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = get_model(embedding_matrix, VOCAB_SIZE)\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSSztQsfRuzJ",
        "outputId": "5eef9e11-8775-4489-b2d0-18af0a3d03b0"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer \"attention\" (type Attention).\n\nDimensions must be equal, but are 50 and 16 for '{{node attention/MatMul}} = BatchMatMulV2[T=DT_FLOAT, adj_x=false, adj_y=true](Placeholder, Placeholder_1)' with input shapes: [?,16,50], [?,50,16].\n\nCall arguments received by layer \"attention\" (type Attention):\n  • inputs=['tf.Tensor(shape=(None, 16, 50), dtype=float32)', 'tf.Tensor(shape=(None, 50, 16), dtype=float32)']\n  • mask=['tf.Tensor(shape=(None, 16), dtype=bool)', 'tf.Tensor(shape=(None, 50), dtype=bool)']\n  • training=None\n  • return_attention_scores=False\n  • use_causal_mask=False",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m get_model(embedding_matrix, VOCAB_SIZE)\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39msummary())\n\u001b[1;32m      4\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39mLEARNING_RATE),\n\u001b[1;32m      5\u001b[0m               loss\u001b[39m=\u001b[39mmasked_loss,\n\u001b[1;32m      6\u001b[0m               metrics\u001b[39m=\u001b[39m[masked_acc, masked_loss])\n",
            "Cell \u001b[0;32mIn[11], line 26\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(embedding_matrix, VOCAB_SIZE)\u001b[0m\n\u001b[1;32m     23\u001b[0m i \u001b[39m=\u001b[39m decoder(i, initial_state\u001b[39m=\u001b[39m[j, k])\n\u001b[1;32m     24\u001b[0m i \u001b[39m=\u001b[39m Dropout(\u001b[39m.3\u001b[39m)(i)\n\u001b[0;32m---> 26\u001b[0m l \u001b[39m=\u001b[39m Attention()([x, i])\n\u001b[1;32m     27\u001b[0m ll \u001b[39m=\u001b[39m Attention()([i, x])\n\u001b[1;32m     29\u001b[0m m \u001b[39m=\u001b[39m Concatenate()([x, i, l, ll])\n",
            "File \u001b[0;32m~/miniconda3/envs/tf_new/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/miniconda3/envs/tf_new/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1973\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1970\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[1;32m   1971\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1972\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m-> 1973\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n\u001b[1;32m   1975\u001b[0m \u001b[39m# Record the current Python stack trace as the creating stacktrace of this\u001b[39;00m\n\u001b[1;32m   1976\u001b[0m \u001b[39m# TF_Operation.\u001b[39;00m\n\u001b[1;32m   1977\u001b[0m \u001b[39mif\u001b[39;00m extract_traceback:\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"attention\" (type Attention).\n\nDimensions must be equal, but are 50 and 16 for '{{node attention/MatMul}} = BatchMatMulV2[T=DT_FLOAT, adj_x=false, adj_y=true](Placeholder, Placeholder_1)' with input shapes: [?,16,50], [?,50,16].\n\nCall arguments received by layer \"attention\" (type Attention):\n  • inputs=['tf.Tensor(shape=(None, 16, 50), dtype=float32)', 'tf.Tensor(shape=(None, 50, 16), dtype=float32)']\n  • mask=['tf.Tensor(shape=(None, 16), dtype=bool)', 'tf.Tensor(shape=(None, 50), dtype=bool)']\n  • training=None\n  • return_attention_scores=False\n  • use_causal_mask=False"
          ]
        }
      ],
      "source": [
        "\n",
        "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "#               loss=masked_loss,\n",
        "#               metrics=[masked_acc])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=masked_loss,\n",
        "              metrics=[masked_acc])\n",
        "\n",
        "\n",
        "# model = tf.keras.models.load_model('/content/drive/MyDrive/cap-gen/2023-05-14 08:04:36.705364-30.tf')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VrFvq8baLFDz"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Example usage\n",
        "initial_lr = LEARNING_RATE\n",
        "decay_rate = -0.001\n",
        "decay_steps = 2\n",
        "\n",
        "decay_callback = LearningRateDecayCallback(initial_lr, decay_rate, decay_steps)\n",
        "\n",
        "os.makedirs('log', exist_ok=True)\n",
        "csv_logger = CSVLogger('./log/training.log')\n",
        "tb_callback = tf.keras.callbacks.TensorBoard('./logs', update_freq=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0nz0_27LUSL",
        "outputId": "bf8e9211-6fa6-4ae8-bb98-9c80c64c976b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.01\n"
          ]
        }
      ],
      "source": [
        "print(initial_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH--P_BE4qSV",
        "outputId": "065b9805-1d36-4554-9e46-658a4f943cef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1195 66\n",
            "119 13\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "print(len(train_data) // EPOCHS, len(val_data) // EPOCHS)\n",
        "\n",
        "steps_per_epoch = int(0.1*(len(train_data) / EPOCHS))\n",
        "validation_steps =  int(.2*(len(val_data) / EPOCHS))\n",
        "print(steps_per_epoch, validation_steps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac3qO85h4qNE",
        "outputId": "630efa8c-3dce-46f4-9cdd-fedda1317108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "119/119 [==============================] - ETA: 0s - loss: 20.1196 - masked_acc: 4.0578e-04 - masked_loss: 20.1200"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r119/119 [==============================] - 268s 2s/step - loss: 20.1196 - masked_acc: 4.0578e-04 - masked_loss: 20.1200 - val_loss: 21.1002 - val_masked_acc: 0.0000e+00 - val_masked_loss: 21.1075\n",
            "Epoch 2/3\n",
            "119/119 [==============================] - 244s 2s/step - loss: 20.5730 - masked_acc: 8.1453e-05 - masked_loss: 20.5780 - val_loss: 21.1443 - val_masked_acc: 0.0000e+00 - val_masked_loss: 21.1778\n",
            "Epoch 3/3\n",
            "119/119 [==============================] - 212s 2s/step - loss: 20.7125 - masked_acc: 0.0000e+00 - masked_loss: 20.7103 - val_loss: 21.0854 - val_masked_acc: 0.0000e+00 - val_masked_loss: 21.1121\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_data,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=val_data,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    validation_steps=validation_steps,\n",
        "                    callbacks=[\n",
        "                        decay_callback,\n",
        "                        csv_logger, create_model_checkpoint(model_name = 'capgen', save_dir = 'checkpoints', monitor = 'masked_acc')\n",
        "                                ]\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVDBU9sFQ4bB",
        "outputId": "e6a46a4b-7a11-4ddb-8222-f51ab57fadc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXqqH-Yd4qKP",
        "outputId": "c0e01f14-cab7-486c-dbec-9bcf0daf88db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 6s 6s/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# model.save(f'/content/drive/MyDrive/cap-gen/{datetime.datetime.now()}-{EPOCHS}.tf')\n",
        "\n",
        "pred = model.predict(test_data.take(1))\n",
        "# print(pred.shape)\n",
        "\n",
        "# start_token_id = word_to_id('startseq') \n",
        "# end_token_id = word_to_id('endseq') \n",
        "\n",
        "\n",
        "\n",
        "# aa = generate_caption(random_image_path, model, tokenizer)\n",
        "# print(aa)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TaXI3HM4qHV",
        "outputId": "0330a2b6-417b-465c-b70e-d28d54b71d10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8, 50, 7653)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SEgrpR5C4qEN"
      },
      "outputs": [],
      "source": [
        "from preprocessing import tokens_to_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "t8Kg89PA8yWK"
      },
      "outputs": [],
      "source": [
        "\n",
        "START_TOKEN = 'startseq'\n",
        "END_TOKEN = 'endseq'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Bz1oGEdS8v7Q"
      },
      "outputs": [],
      "source": [
        "def tokens_to_text(tokens):\n",
        "    words = id_to_word(tokens)\n",
        "    result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "    result = tf.strings.regex_replace(result, f'^ *{START_TOKEN} *', '')\n",
        "    result = tf.strings.regex_replace(result, f' *{END_TOKEN} *$', '')\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jH685-1-qhI",
        "outputId": "1ab2e204-aac3-4a01-d21b-86aba63ec608"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([8, 50])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predd = tf.argmax(pred, axis = -1)\n",
        "predd.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "6HzwY_t14qBZ"
      },
      "outputs": [],
      "source": [
        "rr = tokens_to_text(predd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUKOmqDW9VP-",
        "outputId": "7bb7ca06-7534-4c65-f163-4a8d88a5ec0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([8])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoATojqI9uu-",
        "outputId": "c5e75d90-04ae-4d54-8927-ef6179f515ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8, 2048)\n"
          ]
        }
      ],
      "source": [
        "for (img, txt_in), txt_out in test_data.take(1):\n",
        "    print(img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "H88_RgYW-Cba",
        "outputId": "d20c1075-4510-422f-e898-0fcc5f54043d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ce993c67-0906-462b-bb3d-3e7684b6e8d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>115745</th>\n",
              "      <td>input/flickr30k/images/4761236916.jpg</td>\n",
              "      <td>startseq A dark haired child in swimwear laugh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97590</th>\n",
              "      <td>input/flickr30k/images/4388731466.jpg</td>\n",
              "      <td>startseq Two dark haired men in orange shirts ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114665</th>\n",
              "      <td>input/flickr30k/images/4745027152.jpg</td>\n",
              "      <td>startseq A young lady is colorfully dressed in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9786</th>\n",
              "      <td>input/flickr30k/images/1557838421.jpg</td>\n",
              "      <td>startseq Two dogs wrestle with each other with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28360</th>\n",
              "      <td>input/flickr30k/images/2414352262.jpg</td>\n",
              "      <td>startseq young girl in winter coat jumping off...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce993c67-0906-462b-bb3d-3e7684b6e8d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce993c67-0906-462b-bb3d-3e7684b6e8d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce993c67-0906-462b-bb3d-3e7684b6e8d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                   image_path  \\\n",
              "115745  input/flickr30k/images/4761236916.jpg   \n",
              "97590   input/flickr30k/images/4388731466.jpg   \n",
              "114665  input/flickr30k/images/4745027152.jpg   \n",
              "9786    input/flickr30k/images/1557838421.jpg   \n",
              "28360   input/flickr30k/images/2414352262.jpg   \n",
              "\n",
              "                                                  comment  \n",
              "115745  startseq A dark haired child in swimwear laugh...  \n",
              "97590   startseq Two dark haired men in orange shirts ...  \n",
              "114665  startseq A young lady is colorfully dressed in...  \n",
              "9786    startseq Two dogs wrestle with each other with...  \n",
              "28360   startseq young girl in winter coat jumping off...  "
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-OtR5Ma4p9x",
        "outputId": "386c4aa1-cb98-4237-f429-91cef71c1c59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8,), dtype=string, numpy=\n",
              "array([b'power power power power power power power power power power power power power power power arts arts expressing power conducts power arts power besides learn rolling arts power arts power impeach rolling rolling server trudging power releasing besides lightly rolling trudging impeach conducts wardrobe power power impeach impeach power besides',\n",
              "       b'power power power power power power power power power power power power power power power power arts expressing power conducts power arts power besides teams rolling arts power arts power impeach rolling wardrobe server trudging power couples besides lightly rolling trudging impeach rolling wardrobe power power impeach impeach power besides',\n",
              "       b'power power power power power power power power power power power power power power power arts arts expressing power conducts power arts power besides power rolling arts power arts power impeach conducts rolling server rolling power besides besides write rolling trudging impeach conducts wardrobe power power impeach impeach power besides',\n",
              "       b'power power power power power power power power power power power power power power power arts arts expressing power conducts power arts power power teams rolling arts power arts power impeach rolling lightly server conducts power power besides lightly rolling trudging impeach arts wardrobe power power conducts impeach power await',\n",
              "       b'power power power power power power power power power power power power power power power arts arts expressing power conducts power arts power besides teams rolling arts power arts power impeach rolling lightly server trudging power besides besides expressing rolling trudging impeach arts wardrobe power power conducts impeach power besides',\n",
              "       b'power power power power power power power power power power power power power power power power power expressing power conducts power arts power besides teams rolling arts power arts power impeach rolling wardrobe server trudging power couples besides lightly rolling trudging impeach conducts wardrobe power power conducts impeach power besides',\n",
              "       b'power power power power power power power power power power power power power power power arts arts expressing power conducts power arts power power sun rolling arts power arts power impeach rolling rolling server trudging power besides besides power rolling trudging impeach rolling wardrobe power power impeach impeach power arts',\n",
              "       b'power power power power power power power power power power power power power power power power power expressing power conducts power arts power besides sitar rolling arts power arts power impeach rolling lightly server trudging power besides besides lightly rolling trudging impeach arts wardrobe power power conducts impeach power besides'],\n",
              "      dtype=object)>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "QX164-rr_P98"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from preprocessing import load_images_now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "liRul0Ne_Z2d"
      },
      "outputs": [],
      "source": [
        "start_token = START_TOKEN\n",
        "end_token = END_TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "C_WTYK-39Z9n"
      },
      "outputs": [],
      "source": [
        "# def generate_caption(image_path, model, tokenizer, beam_size=5):\n",
        "#     ii = plt.imread(image_path)\n",
        "#     plt.imshow(ii)\n",
        "\n",
        "#     features = load_images_now(image_path)\n",
        "#     features = tf.reshape(features, (1, features.shape[0]))\n",
        "\n",
        "#     beams = [[start_token]] * beam_size\n",
        "\n",
        "#     for _ in range(MAX_LEN):\n",
        "#         for i, beam in enumerate(beams):\n",
        "#             sequence = tokenizer([beam.decode('utf-8')])\n",
        "#             sequence = tf.pad(sequence, [[0, 0], [0, MAX_LEN - tf.shape(sequence)[1]]])\n",
        "\n",
        "#             logits = model.predict([features, sequence], verbose = 0)\n",
        "#             next_word_idx = tf.argmax(logits, axis=-1)\n",
        "\n",
        "#             next_word = id_to_word(next_word_idx.numpy()[0])\n",
        "\n",
        "#             beams[i].append(next_word)\n",
        "\n",
        "#             beams.sort(key=lambda x: x[-1], reverse=True)\n",
        "\n",
        "#             beams = beams[:beam_size]\n",
        "\n",
        "#         caption = beams[0]\n",
        "#     return ' '.join(caption[1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "B635Fa78A-9h"
      },
      "outputs": [],
      "source": [
        "def generate_caption(image_path):\n",
        "\n",
        "  # Load the image and resize it to 224x224 pixels.\n",
        "  image = tf.io.read_file(image_path)\n",
        "  image = tf.image.decode_jpeg(image, channels=CHANNELS)\n",
        "  image = tf.image.resize(image, (224, 224))\n",
        "\n",
        "  # Get the image features from the ResNet50V2 model.\n",
        "  image_features = resnet(image)\n",
        "\n",
        "  # Get the start and end tokens.\n",
        "  start_token = tf.constant([VOCAB_SIZE - 1], dtype=tf.int32)\n",
        "  end_token = tf.constant([VOCAB_SIZE], dtype=tf.int32)\n",
        "\n",
        "  # Initialize the decoder state.\n",
        "  decoder_state = encoder.initialize_state(image_features)\n",
        "\n",
        "  # Initialize the output sequence.\n",
        "  output_sequence = []\n",
        "\n",
        "  # Generate the caption.\n",
        "  for i in range(MAX_LEN):\n",
        "\n",
        "    # Get the next word.\n",
        "    next_word_logits, decoder_state = decoder(image_features, decoder_state)\n",
        "    next_word = tf.argmax(next_word_logits, axis=1)\n",
        "\n",
        "    # If the next word is the end token, stop generating.\n",
        "    if next_word == end_token:\n",
        "      break\n",
        "\n",
        "    # Add the next word to the output sequence.\n",
        "    output_sequence.append(next_word)\n",
        "\n",
        "  # Convert the output sequence to a string.\n",
        "  output_caption = tokenizer.inverse_transform(output_sequence)\n",
        "\n",
        "  return output_caption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "RNDAMqYZ_No2"
      },
      "outputs": [],
      "source": [
        "random_img_path = test['image_path'].sample(1).values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "YOV6kfvA_sFi",
        "outputId": "cd3e2bea-8a8e-481d-af74-df371a1cebe7"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-13b9f6b7bc26>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_caption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_img_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-a1655cc68d06>\u001b[0m in \u001b[0;36mgenerate_caption\u001b[0;34m(image_path, model, tokenizer)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Loop to generate the caption one word at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mpredicted_word_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model' (type Functional).\n    \n    Input 0 of layer \"lstm\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 50)\n    \n    Call arguments received by layer 'model' (type Functional):\n      • inputs=('tf.Tensor(shape=(None, 2048), dtype=float32)', 'tf.Tensor(shape=(None,), dtype=int32)')\n      • training=False\n      • mask=None\n"
          ]
        }
      ],
      "source": [
        "rr = generate_caption(random_img_path, model, tokenizer)\n",
        "rr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQgQAlZo_5Tq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "tf_new",
      "language": "python",
      "name": "tf_new"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
